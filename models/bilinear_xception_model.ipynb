{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bilinear_xception_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vev5DAYLK5OZ",
        "colab_type": "text"
      },
      "source": [
        "# **Bangkit Final Project: World Coin Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aF2mIOQNC5o",
        "colab_type": "text"
      },
      "source": [
        "# **Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8dZbIdLrLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential, Model, model_from_json, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Lambda, Reshape, concatenate\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.regularizers import Regularizer, l2\n",
        "\n",
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MskslwLsYt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "eefedc71-48ee-4232-e231-4347345f1c0f"
      },
      "source": [
        "# Upload the kaggle.json file from Kaggle account settings page\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f19a13dd-5126-4693-ac4d-f41ee0e6707e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f19a13dd-5126-4693-ac4d-f41ee0e6707e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-mZ_XHMezh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the Kaggle API client\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdSwixL0MUxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_rjYl-NU0_",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS2VsR0CNg0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7071e202-9228-4916-b035-b80eb8289f56"
      },
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d wanderdust/coin-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coin-images.zip to /content\n",
            " 98% 449M/459M [00:08<00:00, 57.2MB/s]\n",
            "100% 459M/459M [00:08<00:00, 54.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_bT4N7OopU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If kaggle is down, mount from drive\n",
        "try:\n",
        "    coin_file = open('/content/coin-images.zip', 'r')\n",
        "    filepath = '/content/coin-images.zip'\n",
        "except FileNotFoundError:\n",
        "    drive.mount('/content/drive')\n",
        "    filepath = '/content/drive/My Drive/Bangkit project/Dataset/coin-images.zip'\n",
        "\n",
        "# Unzip the dataset into folder\n",
        "zip_ref = zipfile.ZipFile(filepath, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2d5YlhRQpK",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGaQrJvGRTG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define directories\n",
        "data_dir = \"/content/coins/data/\"\n",
        "\n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"validation/\"\n",
        "test_dir = data_dir + \"test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZoeHe2hJ-SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BDiwC6MJcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a391630-377f-4ea4-9f2b-cc1ebcab9adf"
      },
      "source": [
        "# Read images from generators\n",
        "batch_size = 32\n",
        "image_width = 299\n",
        "image_height = 299\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6413 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9QD8ft22wk_",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX1T4tt0OrhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d20ddb2-475c-4d18-aaa0-daebb75baf59"
      },
      "source": [
        "# Load base model\n",
        "base_model = Xception(\n",
        "    input_shape=(image_width, image_height, 3),\n",
        "    weights='imagenet',\n",
        "    include_top=False\n",
        ")\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "    # Add regularizer\n",
        "    l2_layer = l2(0.01)\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        base_model.add_loss(lambda layer=layer: l2_layer(layer.kernel))\n",
        "\n",
        "for layer in base_model.layers[:10]:\n",
        "\t\tlayer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "# Reduce dimension\n",
        "x = Conv2D(128, (1,1), activation='relu')(x)\n",
        "\n",
        "# Bilinear pooling\n",
        "\n",
        "# Reshape to (minibatch_size, total_pixels, filter_size)\n",
        "x_detector, shape_detector = x, x.shape\n",
        "x_detector = Reshape([shape_detector[1] * shape_detector[2], shape_detector[-1]])(x_detector)\n",
        "x_extractor, shape_extractor = x, x.shape\n",
        "x_extractor = Reshape([shape_extractor[1] * shape_extractor[2], shape_extractor[-1]])(x_extractor)\n",
        "\n",
        "# Outer product\n",
        "def outer_product(x):\n",
        "    return backend.batch_dot(x[0], x[1], axes=[1,1]) / x[0].get_shape().as_list()[1]\n",
        "x = Lambda(outer_product)([x_detector, x_extractor])\n",
        "\n",
        "# Reshape to (minibatch_size, filter_size_detector*filter_size_extractor)\n",
        "x = Reshape([shape_detector[-1]*shape_extractor[-1]])(x)\n",
        "\n",
        "# Signed square root\n",
        "def signed_sqrt(x):\n",
        "    return backend.sign(x) * backend.sqrt(backend.abs(x)+1e-9)\n",
        "x = Lambda(signed_sqrt)(x)\n",
        "\n",
        "# L2 normalisation\n",
        "def L2_norm(x, axis=-1):\n",
        "    return backend.l2_normalize(x, axis=axis)\n",
        "x = Lambda(L2_norm)(x)\n",
        "\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(211, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 4s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 10, 128)  262272      block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 100, 128)     0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 100, 128)     0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 128, 128)     0           reshape[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 16384)        0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16384)        0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 16384)        0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2048)         33556480    lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          1049088     dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 211)          108243      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 55,837,563\n",
            "Trainable params: 55,754,523\n",
            "Non-trainable params: 83,040\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhZ9bR-PiVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57214453-9afc-4b71-b521-2c8cf198813d"
      },
      "source": [
        "# Callback to reduce learning rate if no improvement in validation loss for certain number of epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-8, verbose=1)\n",
        "\n",
        "# Callback to stop training if no improvement in validation loss for certain number of epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# Callback to save best model weights per epoch\n",
        "weights_filepath = \"best_model_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=weights_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Nadam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    validation_steps=3,\n",
        "    callbacks=[reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3488 - accuracy: 0.0069\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.01042, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 5.3488 - accuracy: 0.0069 - val_loss: 5.3452 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 2/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3179 - accuracy: 0.0137\n",
            "Epoch 00002: val_accuracy did not improve from 0.01042\n",
            "50/50 [==============================] - 56s 1s/step - loss: 5.3179 - accuracy: 0.0137 - val_loss: 5.3211 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2152 - accuracy: 0.0392\n",
            "Epoch 00003: val_accuracy improved from 0.01042 to 0.02083, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 5.2152 - accuracy: 0.0392 - val_loss: 5.3045 - val_accuracy: 0.0208 - lr: 1.0000e-04\n",
            "Epoch 4/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0023 - accuracy: 0.0494\n",
            "Epoch 00004: val_accuracy did not improve from 0.02083\n",
            "50/50 [==============================] - 56s 1s/step - loss: 5.0023 - accuracy: 0.0494 - val_loss: 4.9257 - val_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 5/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.7125 - accuracy: 0.0844\n",
            "Epoch 00005: val_accuracy improved from 0.02083 to 0.06250, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 4.7125 - accuracy: 0.0844 - val_loss: 4.8682 - val_accuracy: 0.0625 - lr: 1.0000e-04\n",
            "Epoch 6/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.3472 - accuracy: 0.1139\n",
            "Epoch 00006: val_accuracy improved from 0.06250 to 0.13542, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 4.3472 - accuracy: 0.1139 - val_loss: 4.4122 - val_accuracy: 0.1354 - lr: 1.0000e-04\n",
            "Epoch 7/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.0474 - accuracy: 0.1500\n",
            "Epoch 00007: val_accuracy improved from 0.13542 to 0.20833, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 59s 1s/step - loss: 4.0474 - accuracy: 0.1500 - val_loss: 3.9269 - val_accuracy: 0.2083 - lr: 1.0000e-04\n",
            "Epoch 8/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.7057 - accuracy: 0.1967\n",
            "Epoch 00008: val_accuracy improved from 0.20833 to 0.21875, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 3.7057 - accuracy: 0.1967 - val_loss: 3.6417 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
            "Epoch 9/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.4551 - accuracy: 0.2256\n",
            "Epoch 00009: val_accuracy improved from 0.21875 to 0.23958, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 3.4551 - accuracy: 0.2256 - val_loss: 3.6574 - val_accuracy: 0.2396 - lr: 1.0000e-04\n",
            "Epoch 10/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.2232 - accuracy: 0.2544\n",
            "Epoch 00010: val_accuracy improved from 0.23958 to 0.33333, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 3.2232 - accuracy: 0.2544 - val_loss: 3.2304 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 11/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.9917 - accuracy: 0.3031\n",
            "Epoch 00011: val_accuracy improved from 0.33333 to 0.52083, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 2.9917 - accuracy: 0.3031 - val_loss: 2.5594 - val_accuracy: 0.5208 - lr: 1.0000e-04\n",
            "Epoch 12/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.7265 - accuracy: 0.3536\n",
            "Epoch 00012: val_accuracy did not improve from 0.52083\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.7265 - accuracy: 0.3536 - val_loss: 2.8995 - val_accuracy: 0.3646 - lr: 1.0000e-04\n",
            "Epoch 13/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.5464 - accuracy: 0.3975\n",
            "Epoch 00013: val_accuracy did not improve from 0.52083\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.5464 - accuracy: 0.3975 - val_loss: 2.5176 - val_accuracy: 0.4688 - lr: 1.0000e-04\n",
            "Epoch 14/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.3315 - accuracy: 0.4263\n",
            "Epoch 00014: val_accuracy improved from 0.52083 to 0.60417, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 59s 1s/step - loss: 2.3315 - accuracy: 0.4263 - val_loss: 2.1032 - val_accuracy: 0.6042 - lr: 1.0000e-04\n",
            "Epoch 15/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.1732 - accuracy: 0.4688\n",
            "Epoch 00015: val_accuracy improved from 0.60417 to 0.65625, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 59s 1s/step - loss: 2.1732 - accuracy: 0.4688 - val_loss: 1.9522 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 16/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.0337 - accuracy: 0.5117\n",
            "Epoch 00016: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.0337 - accuracy: 0.5117 - val_loss: 2.0393 - val_accuracy: 0.5521 - lr: 1.0000e-04\n",
            "Epoch 17/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.8666 - accuracy: 0.5263\n",
            "Epoch 00017: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.8666 - accuracy: 0.5263 - val_loss: 2.0027 - val_accuracy: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 18/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6956 - accuracy: 0.5844\n",
            "Epoch 00018: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.6956 - accuracy: 0.5844 - val_loss: 1.5672 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 19/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6554 - accuracy: 0.5906\n",
            "Epoch 00019: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.6554 - accuracy: 0.5906 - val_loss: 1.6755 - val_accuracy: 0.5938 - lr: 1.0000e-04\n",
            "Epoch 20/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.4927 - accuracy: 0.6135\n",
            "Epoch 00020: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.4927 - accuracy: 0.6135 - val_loss: 1.4970 - val_accuracy: 0.6354 - lr: 1.0000e-04\n",
            "Epoch 21/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3934 - accuracy: 0.6481\n",
            "Epoch 00021: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.3934 - accuracy: 0.6481 - val_loss: 1.4144 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 22/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3478 - accuracy: 0.6538\n",
            "Epoch 00022: val_accuracy improved from 0.65625 to 0.70833, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 1.3478 - accuracy: 0.6538 - val_loss: 1.3957 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 23/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2870 - accuracy: 0.6775\n",
            "Epoch 00023: val_accuracy improved from 0.70833 to 0.71875, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 1.2870 - accuracy: 0.6775 - val_loss: 1.2701 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 24/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1374 - accuracy: 0.7019\n",
            "Epoch 00024: val_accuracy did not improve from 0.71875\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.1374 - accuracy: 0.7019 - val_loss: 1.3230 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 25/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0453 - accuracy: 0.7306\n",
            "Epoch 00025: val_accuracy improved from 0.71875 to 0.72917, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 1.0453 - accuracy: 0.7306 - val_loss: 1.1562 - val_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 26/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9926 - accuracy: 0.7400\n",
            "Epoch 00026: val_accuracy did not improve from 0.72917\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.9926 - accuracy: 0.7400 - val_loss: 1.4006 - val_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 27/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.7412\n",
            "Epoch 00027: val_accuracy did not improve from 0.72917\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.9907 - accuracy: 0.7412 - val_loss: 1.2028 - val_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 28/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.7613\n",
            "Epoch 00028: val_accuracy improved from 0.72917 to 0.81250, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 0.9064 - accuracy: 0.7613 - val_loss: 0.9686 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 29/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8394 - accuracy: 0.7825\n",
            "Epoch 00029: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.8394 - accuracy: 0.7825 - val_loss: 0.9440 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 30/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.7681\n",
            "Epoch 00030: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.8299 - accuracy: 0.7681 - val_loss: 1.1775 - val_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 31/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.7982\n",
            "Epoch 00031: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.7142 - accuracy: 0.7982 - val_loss: 1.1583 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 32/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.8106\n",
            "Epoch 00032: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.7082 - accuracy: 0.8106 - val_loss: 1.0799 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 33/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.8138\n",
            "Epoch 00033: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.6838 - accuracy: 0.8138 - val_loss: 1.0771 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 34/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.8393\n",
            "Epoch 00034: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.6046 - accuracy: 0.8393 - val_loss: 1.3476 - val_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 35/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.8482\n",
            "Epoch 00035: val_accuracy did not improve from 0.81250\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.5772 - accuracy: 0.8482 - val_loss: 0.8454 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 36/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.8406\n",
            "Epoch 00036: val_accuracy improved from 0.81250 to 0.82292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 0.5724 - accuracy: 0.8406 - val_loss: 0.6819 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 37/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8487\n",
            "Epoch 00037: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.5345 - accuracy: 0.8487 - val_loss: 0.8139 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 38/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8531Epoch 39/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8691\n",
            "Epoch 00039: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4803 - accuracy: 0.8691 - val_loss: 0.8650 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 40/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.8631\n",
            "Epoch 00040: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4705 - accuracy: 0.8631 - val_loss: 0.8857 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 41/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8786\n",
            "Epoch 00041: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4347 - accuracy: 0.8786 - val_loss: 1.2086 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 42/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8831\n",
            "Epoch 00042: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4337 - accuracy: 0.8831 - val_loss: 0.8965 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 43/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8788\n",
            "Epoch 00043: val_accuracy improved from 0.82292 to 0.86458, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.4453 - accuracy: 0.8788 - val_loss: 0.6675 - val_accuracy: 0.8646 - lr: 1.0000e-04\n",
            "Epoch 44/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8811\n",
            "Epoch 00044: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4234 - accuracy: 0.8811 - val_loss: 0.7325 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 45/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8975\n",
            "Epoch 00045: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.3792 - accuracy: 0.8975 - val_loss: 0.9610 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 46/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9007\n",
            "Epoch 00046: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.3742 - accuracy: 0.9007 - val_loss: 0.8739 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 47/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8894\n",
            "Epoch 00047: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.3983 - accuracy: 0.8894 - val_loss: 1.0832 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 48/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8937\n",
            "Epoch 00048: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3743 - accuracy: 0.8937 - val_loss: 0.6922 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 49/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.9100\n",
            "Epoch 00049: val_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3259 - accuracy: 0.9100 - val_loss: 0.7307 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 50/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.9144\n",
            "Epoch 00050: val_accuracy improved from 0.86458 to 0.87500, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.3044 - accuracy: 0.9144 - val_loss: 0.6603 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 51/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9162\n",
            "Epoch 00051: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2904 - accuracy: 0.9162 - val_loss: 0.8589 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 52/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.9094\n",
            "Epoch 00052: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.3148 - accuracy: 0.9094 - val_loss: 1.2981 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 53/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.9331\n",
            "Epoch 00053: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.2587 - accuracy: 0.9331 - val_loss: 1.0769 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 54/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.9250\n",
            "Epoch 00054: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.2811 - accuracy: 0.9250 - val_loss: 1.1365 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 55/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9256\n",
            "Epoch 00055: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.2684 - accuracy: 0.9256 - val_loss: 0.9501 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 56/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9362\n",
            "Epoch 00056: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2475 - accuracy: 0.9362 - val_loss: 0.8668 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 57/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9369\n",
            "Epoch 00057: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2385 - accuracy: 0.9369 - val_loss: 0.6601 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 58/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9312\n",
            "Epoch 00058: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2301 - accuracy: 0.9312 - val_loss: 0.5323 - val_accuracy: 0.8646 - lr: 1.0000e-04\n",
            "Epoch 59/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9212\n",
            "Epoch 00059: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2655 - accuracy: 0.9212 - val_loss: 0.7564 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 60/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9344\n",
            "Epoch 00060: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2290 - accuracy: 0.9344 - val_loss: 0.8186 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 61/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9412\n",
            "Epoch 00061: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2270 - accuracy: 0.9412 - val_loss: 0.7737 - val_accuracy: 0.8646 - lr: 1.0000e-04\n",
            "Epoch 62/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9304\n",
            "Epoch 00062: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2401 - accuracy: 0.9304 - val_loss: 0.8962 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 63/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9350\n",
            "Epoch 00063: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2456 - accuracy: 0.9350 - val_loss: 1.1836 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 64/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9450\n",
            "Epoch 00064: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2186 - accuracy: 0.9450 - val_loss: 0.9285 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 65/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9513\n",
            "Epoch 00065: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1864 - accuracy: 0.9513 - val_loss: 1.2147 - val_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 66/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9532\n",
            "Epoch 00066: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1784 - accuracy: 0.9532 - val_loss: 1.2926 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 67/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9538\n",
            "Epoch 00067: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1633 - accuracy: 0.9538 - val_loss: 1.3261 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 68/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9500\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1793 - accuracy: 0.9500 - val_loss: 0.9384 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 69/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9481\n",
            "Epoch 00069: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1831 - accuracy: 0.9481 - val_loss: 0.7947 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 70/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9627\n",
            "Epoch 00070: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1452 - accuracy: 0.9627 - val_loss: 0.7932 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 71/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9469\n",
            "Epoch 00071: val_accuracy improved from 0.87500 to 0.88542, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 56s 1s/step - loss: 0.1811 - accuracy: 0.9469 - val_loss: 0.4522 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 72/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9606\n",
            "Epoch 00072: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1485 - accuracy: 0.9606 - val_loss: 0.9203 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
            "Epoch 73/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9594\n",
            "Epoch 00073: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.1553 - accuracy: 0.9594 - val_loss: 0.9759 - val_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 74/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9625\n",
            "Epoch 00074: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.1268 - accuracy: 0.9625 - val_loss: 0.8355 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
            "Epoch 75/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9594\n",
            "Epoch 00075: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.1365 - accuracy: 0.9594 - val_loss: 0.7028 - val_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 76/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9734\n",
            "Epoch 00076: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.1081 - accuracy: 0.9734 - val_loss: 1.1477 - val_accuracy: 0.7708 - lr: 1.0000e-05\n",
            "Epoch 77/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9715\n",
            "Epoch 00077: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 54s 1s/step - loss: 0.1119 - accuracy: 0.9715 - val_loss: 0.4508 - val_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 78/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9669\n",
            "Epoch 00078: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.1274 - accuracy: 0.9669 - val_loss: 1.0176 - val_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 79/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9656\n",
            "Epoch 00079: val_accuracy did not improve from 0.88542\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.1196 - accuracy: 0.9656 - val_loss: 1.3562 - val_accuracy: 0.7396 - lr: 1.0000e-05\n",
            "Epoch 80/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9650\n",
            "Epoch 00080: val_accuracy improved from 0.88542 to 0.90625, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 0.1158 - accuracy: 0.9650 - val_loss: 0.5857 - val_accuracy: 0.9062 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZTPuGY8rWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "2b6e9085-3a0f-476e-8c01-df5d700c50d5"
      },
      "source": [
        "# Visualise accuracy history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Visualise loss history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIvbXL32hN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save(\"bilinear_xception_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCXE1Nm45huL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c6f389d1-b684-405d-e69c-b22c5b74dedb"
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 171s 850ms/step - loss: 0.0568 - accuracy: 0.9810\n",
            "Training loss:  0.05682571604847908\n",
            "Training accuracy:  0.9809761643409729\n",
            "27/27 [==============================] - 22s 807ms/step - loss: 0.8572 - accuracy: 0.8318\n",
            "Validation loss:  0.8571750521659851\n",
            "Validation accuracy:  0.8317535519599915\n",
            "844/844 [==============================] - 12s 14ms/step - loss: 0.6663 - accuracy: 0.8590\n",
            "Testing loss:  0.6662805080413818\n",
            "Testing accuracy:  0.8590047359466553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztC3j9zTRyES",
        "colab": {}
      },
      "source": [
        "model_best_weights = model\n",
        "\n",
        "# Load best model weights\n",
        "model_best_weights.load_weights(weights_filepath)\n",
        "\n",
        "# Save model\n",
        "model_best_weights.save(\"bilinear_xception_model_best_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed6NgxyJR_Ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1c3a48a0-220e-4ea6-b18a-e86a4ff1b22d"
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model_best_weights.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model_best_weights.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model_best_weights.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 171s 852ms/step - loss: 0.0611 - accuracy: 0.9807\n",
            "Training loss:  0.061105962842702866\n",
            "Training accuracy:  0.9806642532348633\n",
            "27/27 [==============================] - 22s 813ms/step - loss: 0.8576 - accuracy: 0.8235\n",
            "Validation loss:  0.8575711250305176\n",
            "Validation accuracy:  0.8234597444534302\n",
            "844/844 [==============================] - 12s 14ms/step - loss: 0.6663 - accuracy: 0.8590\n",
            "Testing loss:  0.6662799715995789\n",
            "Testing accuracy:  0.8590047359466553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJ6NpZE8AzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test images\n",
        "predictions = []\n",
        "\n",
        "for filename in test_generator.filenames:\n",
        "    img = load_img(test_dir+filename, target_size=(image_width, image_height))\n",
        "    img = img_to_array(img)/255\n",
        "    img_expand = np.expand_dims(img, axis=0)\n",
        "    predictions.append(model.predict(img_expand)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhHvvZGaHKQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get index of largest probability\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get coin directory name from index \n",
        "directories = dict((v, k) for k, v in train_generator.class_indices.items())\n",
        "predicted_dir = [directories.get(k) for k in predicted_indices]\n",
        "\n",
        "# Get label name from coin directory name\n",
        "with open(data_dir + 'cat_to_name.json', 'r') as json_file:\n",
        "    labels = json.load(json_file)\n",
        "predicted_labels = [labels.get(str(k)) for k in predicted_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4DLt4o3H78s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c89504c6-30e1-4dfb-c7f2-5787f62dec89"
      },
      "source": [
        "# Save predicted labels as CSV file\n",
        "filenames = test_generator.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames, \"Predictions\": predicted_labels})\n",
        "results.to_csv(\"bilinear_xception_results.csv\", index=False)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/021__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/022__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/027__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/036__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/005__5 Centavos_brazil.jpg</td>\n",
              "      <td>5 Centavos,Brazilian Real,brazil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Filename                         Predictions\n",
              "0    1/021__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "1    1/022__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "2    1/027__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "3    1/036__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "4  10/005__5 Centavos_brazil.jpg    5 Centavos,Brazilian Real,brazil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF69Ut9iKmJW",
        "colab_type": "text"
      },
      "source": [
        "# **Convert to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEOxwCVQKlpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7efa998-794a-4824-e46e-83b4ee6ee4ab"
      },
      "source": [
        "# Create converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"bilinear_xception_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55904472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX-yMWB34O4C",
        "colab_type": "text"
      },
      "source": [
        "# **Copy model to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcyZNaSi4bkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fc6d294b-ad02-4669-e5ce-de4863965ac2"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp bilinear_xception_model.h5 \"/content/drive/My Drive/Bangkit project/models\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}