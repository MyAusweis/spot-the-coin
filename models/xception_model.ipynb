{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xception_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vev5DAYLK5OZ",
        "colab_type": "text"
      },
      "source": [
        "# **Bangkit Final Project: World Coin Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aF2mIOQNC5o",
        "colab_type": "text"
      },
      "source": [
        "# **Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8dZbIdLrLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import Regularizer, l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MskslwLsYt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c07df816-bd7c-4a85-85e2-27fe059b2e4c"
      },
      "source": [
        "# Upload the kaggle.json file from Kaggle account settings page\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-948055e8-5ddd-4a20-9133-e28c92937db7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-948055e8-5ddd-4a20-9133-e28c92937db7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-mZ_XHMezh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the Kaggle API client\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdSwixL0MUxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_rjYl-NU0_",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS2VsR0CNg0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cd615868-e82e-41f2-82cb-40d6fcef7485"
      },
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d wanderdust/coin-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coin-images.zip to /content\n",
            "100% 459M/459M [00:07<00:00, 73.6MB/s]\n",
            "100% 459M/459M [00:07<00:00, 60.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_bT4N7OopU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If kaggle is down, mount from drive\n",
        "try:\n",
        "    coin_file = open('/content/coin-images.zip', 'r')\n",
        "    filepath = '/content/coin-images.zip'\n",
        "except FileNotFoundError:\n",
        "    # Keep preset values\n",
        "    drive.mount('/content/drive')\n",
        "    filepath = '/content/drive/My Drive/Bangkit project/Dataset/coin-images.zip'\n",
        "\n",
        "# Unzip the dataset into folder\n",
        "zip_ref = zipfile.ZipFile(filepath, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2d5YlhRQpK",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGaQrJvGRTG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define directories\n",
        "data_dir = \"/content/coins/data/\"\n",
        "\n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"validation/\"\n",
        "test_dir = data_dir + \"test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZoeHe2hJ-SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BDiwC6MJcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cc2c98e3-9fda-4952-e49e-85b29b8dfe06"
      },
      "source": [
        "# Read images from generators\n",
        "batch_size = 32\n",
        "image_width = 299\n",
        "image_height = 299\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6413 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9QD8ft22wk_",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX1T4tt0OrhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63a450d1-5ad0-478d-b48a-2d9c36ce8f33"
      },
      "source": [
        "# Load base model\n",
        "base_model = Xception(input_shape=(image_width, image_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "    # Add regularizer\n",
        "    l2_layer = l2(0.01)\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        base_model.add_loss(lambda layer=layer: l2_layer(layer.kernel))\n",
        "\n",
        "for layer in base_model.layers[:10]:\n",
        "\t\tlayer.trainable = False\n",
        "\n",
        "# Custom top classifier for model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(211, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 211)          108243      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,018,811\n",
            "Trainable params: 21,935,771\n",
            "Non-trainable params: 83,040\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhZ9bR-PiVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8587ade8-ebea-4c9d-cc68-c17498564141"
      },
      "source": [
        "# Callback to reduce learning rate if no improvement in validation loss for certain number of epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-8, verbose=1)\n",
        "\n",
        "# Callback to stop training if no improvement in validation loss for certain number of epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# Callback to save best model weights per epoch\n",
        "weights_filepath = \"best_model_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=weights_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Nadam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    validation_steps=3,\n",
        "    callbacks=[reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2903 - accuracy: 0.0253\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.04167, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 5.2903 - accuracy: 0.0253 - val_loss: 5.3344 - val_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 2/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9874 - accuracy: 0.0919\n",
            "Epoch 00002: val_accuracy improved from 0.04167 to 0.06250, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 4.9874 - accuracy: 0.0919 - val_loss: 4.9953 - val_accuracy: 0.0625 - lr: 1.0000e-04\n",
            "Epoch 3/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.5348 - accuracy: 0.1581\n",
            "Epoch 00003: val_accuracy improved from 0.06250 to 0.18750, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 4.5348 - accuracy: 0.1581 - val_loss: 4.5596 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 4/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.9492 - accuracy: 0.2525\n",
            "Epoch 00004: val_accuracy improved from 0.18750 to 0.27083, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 3.9492 - accuracy: 0.2525 - val_loss: 3.9696 - val_accuracy: 0.2708 - lr: 1.0000e-04\n",
            "Epoch 5/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 3.4007 - accuracy: 0.3600\n",
            "Epoch 00005: val_accuracy improved from 0.27083 to 0.39583, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 3.4007 - accuracy: 0.3600 - val_loss: 3.1764 - val_accuracy: 0.3958 - lr: 1.0000e-04\n",
            "Epoch 6/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.9880 - accuracy: 0.4263\n",
            "Epoch 00006: val_accuracy improved from 0.39583 to 0.45833, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 2.9880 - accuracy: 0.4263 - val_loss: 2.8934 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 7/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.5018 - accuracy: 0.5319\n",
            "Epoch 00007: val_accuracy improved from 0.45833 to 0.65625, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.5018 - accuracy: 0.5319 - val_loss: 1.8380 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 8/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.2127 - accuracy: 0.5656\n",
            "Epoch 00008: val_accuracy did not improve from 0.65625\n",
            "50/50 [==============================] - 56s 1s/step - loss: 2.2127 - accuracy: 0.5656 - val_loss: 2.2441 - val_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "Epoch 9/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.8753 - accuracy: 0.6300\n",
            "Epoch 00009: val_accuracy improved from 0.65625 to 0.68750, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.8753 - accuracy: 0.6300 - val_loss: 1.8033 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 10/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6518 - accuracy: 0.6544\n",
            "Epoch 00010: val_accuracy improved from 0.68750 to 0.72917, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 57s 1s/step - loss: 1.6518 - accuracy: 0.6544 - val_loss: 1.6581 - val_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 11/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.4684 - accuracy: 0.6888\n",
            "Epoch 00011: val_accuracy did not improve from 0.72917\n",
            "50/50 [==============================] - 55s 1s/step - loss: 1.4684 - accuracy: 0.6888 - val_loss: 1.7578 - val_accuracy: 0.6042 - lr: 1.0000e-04\n",
            "Epoch 12/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3218 - accuracy: 0.7188\n",
            "Epoch 00012: val_accuracy did not improve from 0.72917\n",
            "50/50 [==============================] - 56s 1s/step - loss: 1.3218 - accuracy: 0.7188 - val_loss: 1.4688 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 13/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1791 - accuracy: 0.7462\n",
            "Epoch 00013: val_accuracy improved from 0.72917 to 0.78125, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 58s 1s/step - loss: 1.1791 - accuracy: 0.7462 - val_loss: 1.1784 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 14/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1227 - accuracy: 0.7483\n",
            "Epoch 00014: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 55s 1s/step - loss: 1.1227 - accuracy: 0.7483 - val_loss: 1.3052 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 15/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9949 - accuracy: 0.7744\n",
            "Epoch 00015: val_accuracy did not improve from 0.78125\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.9949 - accuracy: 0.7744 - val_loss: 0.9899 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 16/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8576 - accuracy: 0.8056\n",
            "Epoch 00016: val_accuracy improved from 0.78125 to 0.79167, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 55s 1s/step - loss: 0.8576 - accuracy: 0.8056 - val_loss: 1.0038 - val_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 17/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.8090\n",
            "Epoch 00017: val_accuracy did not improve from 0.79167\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.8391 - accuracy: 0.8090 - val_loss: 1.3193 - val_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 18/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7942 - accuracy: 0.8096\n",
            "Epoch 00018: val_accuracy improved from 0.79167 to 0.82292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.7942 - accuracy: 0.8096 - val_loss: 0.9108 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 19/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.8368\n",
            "Epoch 00019: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.6954 - accuracy: 0.8368 - val_loss: 0.9459 - val_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 20/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.8600\n",
            "Epoch 00020: val_accuracy did not improve from 0.82292\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.6320 - accuracy: 0.8600 - val_loss: 0.9933 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 21/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.8564\n",
            "Epoch 00021: val_accuracy improved from 0.82292 to 0.84375, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.5972 - accuracy: 0.8564 - val_loss: 0.6798 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 22/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.8519\n",
            "Epoch 00022: val_accuracy did not improve from 0.84375\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.6004 - accuracy: 0.8519 - val_loss: 0.9679 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 23/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8731\n",
            "Epoch 00023: val_accuracy did not improve from 0.84375\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.5242 - accuracy: 0.8731 - val_loss: 1.2333 - val_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 24/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.8838\n",
            "Epoch 00024: val_accuracy did not improve from 0.84375\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.4899 - accuracy: 0.8838 - val_loss: 0.7726 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 25/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8775\n",
            "Epoch 00025: val_accuracy improved from 0.84375 to 0.85417, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.4564 - accuracy: 0.8775 - val_loss: 0.6122 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 26/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.8906\n",
            "Epoch 00026: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.4645 - accuracy: 0.8906 - val_loss: 0.9084 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 27/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.8900\n",
            "Epoch 00027: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.4314 - accuracy: 0.8900 - val_loss: 0.9057 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 28/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.9094\n",
            "Epoch 00028: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3837 - accuracy: 0.9094 - val_loss: 0.9778 - val_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 29/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8894\n",
            "Epoch 00029: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.4103 - accuracy: 0.8894 - val_loss: 1.0206 - val_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 30/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.9106\n",
            "Epoch 00030: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3731 - accuracy: 0.9106 - val_loss: 0.8127 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 31/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.9102\n",
            "Epoch 00031: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3664 - accuracy: 0.9102 - val_loss: 0.7925 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 32/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.9125\n",
            "Epoch 00032: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3496 - accuracy: 0.9125 - val_loss: 0.6157 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 33/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.9212\n",
            "Epoch 00033: val_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3278 - accuracy: 0.9212 - val_loss: 0.7760 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 34/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.9241\n",
            "Epoch 00034: val_accuracy improved from 0.85417 to 0.87500, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.3180 - accuracy: 0.9241 - val_loss: 0.5222 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 35/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.9300\n",
            "Epoch 00035: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2732 - accuracy: 0.9300 - val_loss: 0.5996 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 36/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9374\n",
            "Epoch 00036: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2637 - accuracy: 0.9374 - val_loss: 0.9597 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 37/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.9300\n",
            "Epoch 00037: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2885 - accuracy: 0.9300 - val_loss: 0.9107 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 38/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9424\n",
            "Epoch 00038: val_accuracy did not improve from 0.87500\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2239 - accuracy: 0.9424 - val_loss: 0.7834 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 39/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9281\n",
            "Epoch 00039: val_accuracy improved from 0.87500 to 0.90625, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.2560 - accuracy: 0.9281 - val_loss: 0.3949 - val_accuracy: 0.9062 - lr: 1.0000e-04\n",
            "Epoch 40/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9450\n",
            "Epoch 00040: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2262 - accuracy: 0.9450 - val_loss: 0.8216 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 41/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9581\n",
            "Epoch 00041: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1841 - accuracy: 0.9581 - val_loss: 0.6691 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 42/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9425\n",
            "Epoch 00042: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2047 - accuracy: 0.9425 - val_loss: 0.7842 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 43/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9456\n",
            "Epoch 00043: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.2047 - accuracy: 0.9456 - val_loss: 0.6305 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 44/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9588\n",
            "Epoch 00044: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1706 - accuracy: 0.9588 - val_loss: 0.8929 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 45/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9531\n",
            "Epoch 00045: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1807 - accuracy: 0.9531 - val_loss: 0.6034 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 46/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.9481\n",
            "Epoch 00046: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1981 - accuracy: 0.9481 - val_loss: 0.7264 - val_accuracy: 0.8646 - lr: 1.0000e-04\n",
            "Epoch 47/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9532\n",
            "Epoch 00047: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1677 - accuracy: 0.9532 - val_loss: 0.6751 - val_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 48/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9570\n",
            "Epoch 00048: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 51s 1s/step - loss: 0.1710 - accuracy: 0.9570 - val_loss: 0.8103 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 49/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9638\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1454 - accuracy: 0.9638 - val_loss: 1.0332 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 50/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9606\n",
            "Epoch 00050: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1427 - accuracy: 0.9606 - val_loss: 0.8179 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 51/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9606\n",
            "Epoch 00051: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1463 - accuracy: 0.9606 - val_loss: 0.6097 - val_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 52/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9675\n",
            "Epoch 00052: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1294 - accuracy: 0.9675 - val_loss: 0.5487 - val_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 53/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9744\n",
            "Epoch 00053: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.1119 - accuracy: 0.9744 - val_loss: 0.4427 - val_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 54/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9675\n",
            "Epoch 00054: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1110 - accuracy: 0.9675 - val_loss: 0.8169 - val_accuracy: 0.8542 - lr: 1.0000e-05\n",
            "Epoch 55/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9760\n",
            "Epoch 00055: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1083 - accuracy: 0.9760 - val_loss: 0.5420 - val_accuracy: 0.8854 - lr: 1.0000e-05\n",
            "Epoch 56/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9769\n",
            "Epoch 00056: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1067 - accuracy: 0.9769 - val_loss: 0.8830 - val_accuracy: 0.8021 - lr: 1.0000e-05\n",
            "Epoch 57/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9694\n",
            "Epoch 00057: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1168 - accuracy: 0.9694 - val_loss: 0.8456 - val_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 58/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9772\n",
            "Epoch 00058: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1042 - accuracy: 0.9772 - val_loss: 0.7675 - val_accuracy: 0.8229 - lr: 1.0000e-05\n",
            "Epoch 59/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9722\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 51s 1s/step - loss: 0.1049 - accuracy: 0.9722 - val_loss: 0.7360 - val_accuracy: 0.8542 - lr: 1.0000e-05\n",
            "Epoch 60/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9715\n",
            "Epoch 00060: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 51s 1s/step - loss: 0.1132 - accuracy: 0.9715 - val_loss: 0.8785 - val_accuracy: 0.8333 - lr: 1.0000e-06\n",
            "Epoch 61/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9769\n",
            "Epoch 00061: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1080 - accuracy: 0.9769 - val_loss: 0.7205 - val_accuracy: 0.8854 - lr: 1.0000e-06\n",
            "Epoch 62/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9663\n",
            "Epoch 00062: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1125 - accuracy: 0.9663 - val_loss: 0.8963 - val_accuracy: 0.8021 - lr: 1.0000e-06\n",
            "Epoch 63/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9756\n",
            "Epoch 00063: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.0979 - accuracy: 0.9756 - val_loss: 0.3712 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
            "Epoch 64/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9750\n",
            "Epoch 00064: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.7907 - val_accuracy: 0.8229 - lr: 1.0000e-06\n",
            "Epoch 65/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9791\n",
            "Epoch 00065: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 51s 1s/step - loss: 0.1098 - accuracy: 0.9791 - val_loss: 0.7855 - val_accuracy: 0.8125 - lr: 1.0000e-06\n",
            "Epoch 66/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9744\n",
            "Epoch 00066: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1124 - accuracy: 0.9744 - val_loss: 0.6130 - val_accuracy: 0.8542 - lr: 1.0000e-06\n",
            "Epoch 67/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9762\n",
            "Epoch 00067: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.0952 - accuracy: 0.9762 - val_loss: 0.7091 - val_accuracy: 0.7500 - lr: 1.0000e-06\n",
            "Epoch 68/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9675\n",
            "Epoch 00068: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1123 - accuracy: 0.9675 - val_loss: 0.7023 - val_accuracy: 0.8125 - lr: 1.0000e-06\n",
            "Epoch 69/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9725\n",
            "Epoch 00069: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1101 - accuracy: 0.9725 - val_loss: 0.6590 - val_accuracy: 0.8438 - lr: 1.0000e-06\n",
            "Epoch 70/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9656\n",
            "Epoch 00070: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1278 - accuracy: 0.9656 - val_loss: 0.6082 - val_accuracy: 0.8854 - lr: 1.0000e-06\n",
            "Epoch 71/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9785\n",
            "Epoch 00071: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1022 - accuracy: 0.9785 - val_loss: 0.9355 - val_accuracy: 0.7812 - lr: 1.0000e-06\n",
            "Epoch 72/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9719\n",
            "Epoch 00072: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1094 - accuracy: 0.9719 - val_loss: 0.7374 - val_accuracy: 0.8542 - lr: 1.0000e-06\n",
            "Epoch 73/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9737\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1045 - accuracy: 0.9737 - val_loss: 0.8424 - val_accuracy: 0.8125 - lr: 1.0000e-06\n",
            "Epoch 74/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9688\n",
            "Epoch 00074: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1133 - accuracy: 0.9688 - val_loss: 0.7708 - val_accuracy: 0.8333 - lr: 1.0000e-07\n",
            "Epoch 75/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9719\n",
            "Epoch 00075: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1151 - accuracy: 0.9719 - val_loss: 0.6535 - val_accuracy: 0.8438 - lr: 1.0000e-07\n",
            "Epoch 76/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9712\n",
            "Epoch 00076: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1120 - accuracy: 0.9712 - val_loss: 0.5644 - val_accuracy: 0.8646 - lr: 1.0000e-07\n",
            "Epoch 77/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9715\n",
            "Epoch 00077: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 51s 1s/step - loss: 0.1075 - accuracy: 0.9715 - val_loss: 0.6490 - val_accuracy: 0.8438 - lr: 1.0000e-07\n",
            "Epoch 78/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9775\n",
            "Epoch 00078: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.0909 - accuracy: 0.9775 - val_loss: 0.8402 - val_accuracy: 0.8125 - lr: 1.0000e-07\n",
            "Epoch 79/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9744\n",
            "Epoch 00079: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.1063 - accuracy: 0.9744 - val_loss: 0.6295 - val_accuracy: 0.8333 - lr: 1.0000e-07\n",
            "Epoch 80/80\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9762\n",
            "Epoch 00080: val_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 52s 1s/step - loss: 0.0960 - accuracy: 0.9762 - val_loss: 0.8145 - val_accuracy: 0.8229 - lr: 1.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZTPuGY8rWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "604ba66d-d329-4914-fa07-75574bea9a59"
      },
      "source": [
        "# Visualise accuracy history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Visualise loss history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIvbXL32hN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save(\"xception_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCXE1Nm45huL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fc1b9b98-b977-496b-ba72-40e52a442ae4"
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 157s 781ms/step - loss: 0.0553 - accuracy: 0.9821\n",
            "Training loss:  0.055277835577726364\n",
            "Training accuracy:  0.9820677042007446\n",
            "27/27 [==============================] - 20s 743ms/step - loss: 0.7157 - accuracy: 0.8483\n",
            "Validation loss:  0.715654730796814\n",
            "Validation accuracy:  0.8483412265777588\n",
            "844/844 [==============================] - 10s 12ms/step - loss: 0.5830 - accuracy: 0.8590\n",
            "Testing loss:  0.5829501748085022\n",
            "Testing accuracy:  0.8590047359466553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztC3j9zTRyES",
        "colab": {}
      },
      "source": [
        "model_best_weights = model\n",
        "\n",
        "# Load best model weights\n",
        "model_best_weights.load_weights(weights_filepath)\n",
        "\n",
        "# Save model\n",
        "model_best_weights.save(\"xception_model_best_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed6NgxyJR_Ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3519f96a-72a3-46bd-f5eb-fa82ca77abca"
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model_best_weights.evaluate(train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model_best_weights.evaluate(validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model_best_weights.evaluate(test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 157s 779ms/step - loss: 0.1313 - accuracy: 0.9640\n",
            "Training loss:  0.13125017285346985\n",
            "Training accuracy:  0.9639794230461121\n",
            "27/27 [==============================] - 20s 738ms/step - loss: 0.7434 - accuracy: 0.8140\n",
            "Validation loss:  0.7433925867080688\n",
            "Validation accuracy:  0.8139810562133789\n",
            "844/844 [==============================] - 10s 12ms/step - loss: 0.6455 - accuracy: 0.8436\n",
            "Testing loss:  0.645516574382782\n",
            "Testing accuracy:  0.8436018824577332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJ6NpZE8AzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test images\n",
        "predictions = []\n",
        "\n",
        "for filename in test_generator.filenames:\n",
        "    img = load_img(test_dir+filename, target_size=(image_width, image_height))\n",
        "    img = img_to_array(img)/255\n",
        "    img_expand = np.expand_dims(img, axis=0)\n",
        "    predictions.append(model.predict(img_expand)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhHvvZGaHKQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get index of largest probability\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get coin directory name from index \n",
        "directories = dict((v, k) for k, v in train_generator.class_indices.items())\n",
        "predicted_dir = [directories.get(k) for k in predicted_indices]\n",
        "\n",
        "# Get label name from coin directory name\n",
        "with open(data_dir + 'cat_to_name.json', 'r') as json_file:\n",
        "    labels = json.load(json_file)\n",
        "predicted_labels = [labels.get(str(k)) for k in predicted_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4DLt4o3H78s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "060a1528-c036-4b6e-e369-88ce3510ee56"
      },
      "source": [
        "# Save predicted labels as CSV file\n",
        "filenames = test_generator.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames, \"Predictions\": predicted_labels})\n",
        "results.to_csv(\"xception_results.csv\", index=False)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/021__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/022__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/027__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/036__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/005__5 Centavos_brazil.jpg</td>\n",
              "      <td>5 Centavos,Brazilian Real,brazil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Filename                         Predictions\n",
              "0    1/021__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "1    1/022__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "2    1/027__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "3    1/036__1 Cent_australia.jpg  1 Cent,Australian dollar,australia\n",
              "4  10/005__5 Centavos_brazil.jpg    5 Centavos,Brazilian Real,brazil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZlj71Kl_2WO",
        "colab_type": "text"
      },
      "source": [
        "# **Convert to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVWQuD08_1hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"xception_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX-yMWB34O4C",
        "colab_type": "text"
      },
      "source": [
        "# **Copy model to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcyZNaSi4bkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9e37aff0-0e4a-4eb2-bef2-470fae4cb2de"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp xception_model.h5 \"/content/drive/My Drive/Bangkit project/models\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}