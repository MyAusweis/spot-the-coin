{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knowledge_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vev5DAYLK5OZ",
        "colab_type": "text"
      },
      "source": [
        "# **Bangkit Final Project: World Coin Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aF2mIOQNC5o",
        "colab_type": "text"
      },
      "source": [
        "# **Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8dZbIdLrLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential, Model, model_from_json, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Lambda, Reshape, Activation, Concatenate\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import Regularizer, l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "\n",
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MskslwLsYt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "98277f00-102f-461a-b69a-3a4e81245d57"
      },
      "source": [
        "# Upload the kaggle.json file from Kaggle account settings page\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56fad913-dd37-482b-8920-8dbf1eb460db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56fad913-dd37-482b-8920-8dbf1eb460db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-mZ_XHMezh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the Kaggle API client\n",
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdSwixL0MUxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo_rjYl-NU0_",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS2VsR0CNg0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5716d93d-f060-423b-89d3-7cff3da59c7f"
      },
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d wanderdust/coin-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coin-images.zip to /content\n",
            " 96% 442M/459M [00:02<00:00, 211MB/s]\n",
            "100% 459M/459M [00:02<00:00, 172MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_bT4N7OopU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If kaggle is down, mount from drive\n",
        "try:\n",
        "    coin_file = open('/content/coin-images.zip', 'r')\n",
        "    filepath = '/content/coin-images.zip'\n",
        "except FileNotFoundError:\n",
        "    # Keep preset values\n",
        "    drive.mount('/content/drive')\n",
        "    filepath = '/content/drive/My Drive/Bangkit project/Dataset/coin-images.zip'\n",
        "\n",
        "# Unzip the dataset into folder\n",
        "zip_ref = zipfile.ZipFile(filepath, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt2d5YlhRQpK",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGaQrJvGRTG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define directories\n",
        "data_dir = \"/content/coins/data/\"\n",
        "\n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"validation/\"\n",
        "test_dir = data_dir + \"test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZoeHe2hJ-SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=360,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      brightness_range=[0.8,1.2],\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      featurewise_std_normalization=False,\n",
        "      featurewise_center=False,\n",
        "      samplewise_std_normalization=False,\n",
        "      samplewise_center=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BDiwC6MJcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5f073004-8192-4f34-ec6c-46efb3cce640"
      },
      "source": [
        "# Read images from generators\n",
        "batch_size = 32\n",
        "image_width = 224\n",
        "image_height = 224\n",
        "num_classes = 211\n",
        "\n",
        "student_train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size,\n",
        "      seed=42\n",
        ")\n",
        "\n",
        "student_validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size,\n",
        "      seed=42\n",
        ")\n",
        "\n",
        "student_test_generator = test_datagen.flow_from_directory(\n",
        "      test_dir,\n",
        "      target_size=(image_width, image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6413 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVCV1N_ZC4b_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ffe107f5-1f2d-40dd-8664-7e795464ea4b"
      },
      "source": [
        "# Read images from generators\n",
        "teacher_image_width = 299\n",
        "teacher_image_height = 299\n",
        "\n",
        "teacher_train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size=(teacher_image_width, teacher_image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size,\n",
        "      seed=42\n",
        ")\n",
        "\n",
        "teacher_validation_generator = validation_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size=(teacher_image_width, teacher_image_height),\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=batch_size,\n",
        "      seed=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6413 images belonging to 211 classes.\n",
            "Found 844 images belonging to 211 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJaETe9FtSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_generator(gen_x1, gen_x2):\n",
        "    while True:\n",
        "        x1 = gen_x1.__next__()\n",
        "        x2 = gen_x2.__next__()\n",
        "        dummy_y = np.zeros((x1[0].shape[0], image_width, image_height))\n",
        "        yield [x1[0], x2[0], x1[1]], [dummy_y, x1[1]]\n",
        "\n",
        "train_generator = generate_generator(student_train_generator, teacher_train_generator)\n",
        "validation_generator = generate_generator(student_validation_generator, teacher_validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9QD8ft22wk_",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlz4NbGNwQZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c88c39c7-16a4-4af6-be7e-fb105470f286"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL2M8lYDkPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load teacher model\n",
        "teacher_model_path = \"/content/drive/My Drive/Bangkit project/models/ensemble_model.h5\"\n",
        "teacher_model = load_model(teacher_model_path, compile=False)\n",
        "\n",
        "for layer in teacher_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "temperature = 5\n",
        "\n",
        "# Create model to get logits from teacher model\n",
        "teacher_model.layers.pop()\n",
        "teacher_logits = teacher_model.layers[-1].output\n",
        "teacher_logits_T = Lambda(lambda x: x / temperature)(teacher_logits)\n",
        "teacher_probabilities_T = Activation('softmax', name='teacher_probabilities_T')(teacher_logits_T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX1T4tt0OrhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd2abf02-ce33-4c60-c282-0d20ff6268ca"
      },
      "source": [
        "# Load base model\n",
        "base_model = MobileNetV2(input_shape=(image_width, image_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "    # Add regularizer\n",
        "    l2_layer = l2(0.01)\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        base_model.add_loss(lambda layer=layer: l2_layer(layer.kernel))\n",
        "\n",
        "for layer in base_model.layers[:10]:\n",
        "\t\tlayer.trainable = False\n",
        "\n",
        "# Custom top classifier for model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.55)(x)\n",
        "\n",
        "# Usual probabilities\n",
        "logits = Dense(num_classes, activation=None)(x)\n",
        "probabilities = Activation('softmax', name='probabilities')(logits)\n",
        "\n",
        "# Softed probabilities\n",
        "logits_T = Lambda(lambda x: x / temperature)(logits)\n",
        "probabilities_T = Activation('softmax', name='probabilities_T')(logits_T)\n",
        "\n",
        "# Student model\n",
        "student_model = Model(inputs=base_model.inputs, outputs=probabilities)\n",
        "student_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          655872      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 211)          108243      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "probabilities (Activation)      (None, 211)          0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,022,099\n",
            "Trainable params: 2,986,163\n",
            "Non-trainable params: 35,936\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvNfZRxcqohc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de059fa2-8b3f-43d5-f83c-cdf3b4ab11c8"
      },
      "source": [
        "def knowledge_distillation_loss(input_distillation, lambda_factor=0.9):\n",
        "    y_pred, y_true, y_soft, y_pred_soft = input_distillation\n",
        "    # Loss is not scaled with temperature^2 because it leads to worse results\n",
        "    return ((1 - lambda_factor) * categorical_crossentropy(y_true, y_pred) +\n",
        "            lambda_factor * categorical_crossentropy(y_soft, y_pred_soft))\n",
        "\n",
        "# Train model\n",
        "input_true = Input(shape=(211), name='input_true')\n",
        "output_loss = Lambda(knowledge_distillation_loss, output_shape=(1,), name='output_loss')(\n",
        "    [probabilities, input_true, teacher_probabilities_T, probabilities_T]\n",
        ")\n",
        "inputs = [base_model.input, teacher_model.input, input_true]\n",
        "outputs = [output_loss, probabilities]\n",
        "train_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "train_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          655872      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "xception (Model)                (None, 211)          22018811    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception (Model)               (None, 211)          22960115    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bilinear_xception (Model)       (None, 211)          55837563    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 211)          108243      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_1 (Average)             (None, 211)          0           xception[1][0]                   \n",
            "                                                                 inception[1][0]                  \n",
            "                                                                 bilinear_xception[1][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 211)          0           average_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 211)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "probabilities (Activation)      (None, 211)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_true (InputLayer)         [(None, 211)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "teacher_probabilities_T (Activa (None, 211)          0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "probabilities_T (Activation)    (None, 211)          0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output_loss (Lambda)            (None,)              0           probabilities[0][0]              \n",
            "                                                                 input_true[0][0]                 \n",
            "                                                                 teacher_probabilities_T[0][0]    \n",
            "                                                                 probabilities_T[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 103,838,588\n",
            "Trainable params: 2,986,163\n",
            "Non-trainable params: 100,852,425\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn0LV9Ygpm-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "\t\"output_loss\": lambda y_true, y_pred: y_pred,\n",
        "\t\"probabilities\": None\n",
        "}\n",
        "loss_weights = {\"output_loss\": 1.0, \"probabilities\": 0.0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhZ9bR-PiVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83d166bd-404e-41c5-b041-b75f46e51dc8"
      },
      "source": [
        "# Callback to reduce learning rate if no improvement in validation loss for certain number of epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-8, verbose=1)\n",
        "\n",
        "# Callback to stop training if no improvement in validation loss for certain number of epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# Callback to save best model weights per epoch\n",
        "weights_filepath = \"best_model_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=weights_filepath,\n",
        "    monitor='val_probabilities_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "train_model.compile(loss=losses,\n",
        "              loss_weights=loss_weights,\n",
        "              optimizer=Nadam(lr=0.0001),\n",
        "              metrics={'probabilities': 'accuracy'})\n",
        "\n",
        "history = train_model.fit(\n",
        "    train_generator,\n",
        "    epochs=120,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    validation_steps=3,\n",
        "    callbacks=[reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3790 - output_loss_loss: 5.3790 - probabilities_accuracy: 0.0056\n",
            "Epoch 00001: val_probabilities_accuracy improved from -inf to 0.01042, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 88s 2s/step - loss: 5.3790 - output_loss_loss: 5.3790 - probabilities_accuracy: 0.0056 - val_loss: 5.3765 - val_output_loss_loss: 5.3765 - val_probabilities_accuracy: 0.0104 - lr: 1.0000e-04\n",
            "Epoch 2/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3535 - output_loss_loss: 5.3535 - probabilities_accuracy: 0.0113\n",
            "Epoch 00002: val_probabilities_accuracy improved from 0.01042 to 0.04167, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.3535 - output_loss_loss: 5.3535 - probabilities_accuracy: 0.0113 - val_loss: 5.3676 - val_output_loss_loss: 5.3676 - val_probabilities_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 3/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3430 - output_loss_loss: 5.3430 - probabilities_accuracy: 0.0262\n",
            "Epoch 00003: val_probabilities_accuracy did not improve from 0.04167\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.3430 - output_loss_loss: 5.3430 - probabilities_accuracy: 0.0262 - val_loss: 5.3484 - val_output_loss_loss: 5.3484 - val_probabilities_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 4/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3357 - output_loss_loss: 5.3357 - probabilities_accuracy: 0.0494\n",
            "Epoch 00004: val_probabilities_accuracy did not improve from 0.04167\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.3357 - output_loss_loss: 5.3357 - probabilities_accuracy: 0.0494 - val_loss: 5.3616 - val_output_loss_loss: 5.3616 - val_probabilities_accuracy: 0.0208 - lr: 1.0000e-04\n",
            "Epoch 5/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3178 - output_loss_loss: 5.3178 - probabilities_accuracy: 0.0715\n",
            "Epoch 00005: val_probabilities_accuracy improved from 0.04167 to 0.05208, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.3178 - output_loss_loss: 5.3178 - probabilities_accuracy: 0.0715 - val_loss: 5.3350 - val_output_loss_loss: 5.3350 - val_probabilities_accuracy: 0.0521 - lr: 1.0000e-04\n",
            "Epoch 6/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.3029 - output_loss_loss: 5.3029 - probabilities_accuracy: 0.1037\n",
            "Epoch 00006: val_probabilities_accuracy did not improve from 0.05208\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.3029 - output_loss_loss: 5.3029 - probabilities_accuracy: 0.1037 - val_loss: 5.3459 - val_output_loss_loss: 5.3459 - val_probabilities_accuracy: 0.0417 - lr: 1.0000e-04\n",
            "Epoch 7/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2899 - output_loss_loss: 5.2899 - probabilities_accuracy: 0.1256\n",
            "Epoch 00007: val_probabilities_accuracy improved from 0.05208 to 0.06579, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.2899 - output_loss_loss: 5.2899 - probabilities_accuracy: 0.1256 - val_loss: 5.3327 - val_output_loss_loss: 5.3327 - val_probabilities_accuracy: 0.0658 - lr: 1.0000e-04\n",
            "Epoch 8/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2769 - output_loss_loss: 5.2769 - probabilities_accuracy: 0.1412\n",
            "Epoch 00008: val_probabilities_accuracy did not improve from 0.06579\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.2769 - output_loss_loss: 5.2769 - probabilities_accuracy: 0.1412 - val_loss: 5.3189 - val_output_loss_loss: 5.3189 - val_probabilities_accuracy: 0.0312 - lr: 1.0000e-04\n",
            "Epoch 9/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2463 - output_loss_loss: 5.2463 - probabilities_accuracy: 0.2176\n",
            "Epoch 00009: val_probabilities_accuracy improved from 0.06579 to 0.09375, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 84s 2s/step - loss: 5.2463 - output_loss_loss: 5.2463 - probabilities_accuracy: 0.2176 - val_loss: 5.2905 - val_output_loss_loss: 5.2905 - val_probabilities_accuracy: 0.0938 - lr: 1.0000e-04\n",
            "Epoch 10/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2346 - output_loss_loss: 5.2346 - probabilities_accuracy: 0.2169\n",
            "Epoch 00010: val_probabilities_accuracy improved from 0.09375 to 0.10417, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 86s 2s/step - loss: 5.2346 - output_loss_loss: 5.2346 - probabilities_accuracy: 0.2169 - val_loss: 5.3012 - val_output_loss_loss: 5.3012 - val_probabilities_accuracy: 0.1042 - lr: 1.0000e-04\n",
            "Epoch 11/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2192 - output_loss_loss: 5.2192 - probabilities_accuracy: 0.2594\n",
            "Epoch 00011: val_probabilities_accuracy did not improve from 0.10417\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.2192 - output_loss_loss: 5.2192 - probabilities_accuracy: 0.2594 - val_loss: 5.3078 - val_output_loss_loss: 5.3078 - val_probabilities_accuracy: 0.0833 - lr: 1.0000e-04\n",
            "Epoch 12/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.2027 - output_loss_loss: 5.2027 - probabilities_accuracy: 0.2700\n",
            "Epoch 00012: val_probabilities_accuracy improved from 0.10417 to 0.14583, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.2027 - output_loss_loss: 5.2027 - probabilities_accuracy: 0.2700 - val_loss: 5.2804 - val_output_loss_loss: 5.2804 - val_probabilities_accuracy: 0.1458 - lr: 1.0000e-04\n",
            "Epoch 13/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1688 - output_loss_loss: 5.1688 - probabilities_accuracy: 0.3517\n",
            "Epoch 00013: val_probabilities_accuracy improved from 0.14583 to 0.16667, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 84s 2s/step - loss: 5.1688 - output_loss_loss: 5.1688 - probabilities_accuracy: 0.3517 - val_loss: 5.2593 - val_output_loss_loss: 5.2593 - val_probabilities_accuracy: 0.1667 - lr: 1.0000e-04\n",
            "Epoch 14/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1655 - output_loss_loss: 5.1655 - probabilities_accuracy: 0.3625\n",
            "Epoch 00014: val_probabilities_accuracy improved from 0.16667 to 0.23684, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 84s 2s/step - loss: 5.1655 - output_loss_loss: 5.1655 - probabilities_accuracy: 0.3625 - val_loss: 5.2475 - val_output_loss_loss: 5.2475 - val_probabilities_accuracy: 0.2368 - lr: 1.0000e-04\n",
            "Epoch 15/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1485 - output_loss_loss: 5.1485 - probabilities_accuracy: 0.3956\n",
            "Epoch 00015: val_probabilities_accuracy did not improve from 0.23684\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.1485 - output_loss_loss: 5.1485 - probabilities_accuracy: 0.3956 - val_loss: 5.2442 - val_output_loss_loss: 5.2442 - val_probabilities_accuracy: 0.1146 - lr: 1.0000e-04\n",
            "Epoch 16/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1474 - output_loss_loss: 5.1474 - probabilities_accuracy: 0.3963\n",
            "Epoch 00016: val_probabilities_accuracy did not improve from 0.23684\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.1474 - output_loss_loss: 5.1474 - probabilities_accuracy: 0.3963 - val_loss: 5.2387 - val_output_loss_loss: 5.2387 - val_probabilities_accuracy: 0.2292 - lr: 1.0000e-04\n",
            "Epoch 17/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1184 - output_loss_loss: 5.1184 - probabilities_accuracy: 0.4617\n",
            "Epoch 00017: val_probabilities_accuracy did not improve from 0.23684\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.1184 - output_loss_loss: 5.1184 - probabilities_accuracy: 0.4617 - val_loss: 5.2297 - val_output_loss_loss: 5.2297 - val_probabilities_accuracy: 0.1979 - lr: 1.0000e-04\n",
            "Epoch 18/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1078 - output_loss_loss: 5.1078 - probabilities_accuracy: 0.4800\n",
            "Epoch 00018: val_probabilities_accuracy improved from 0.23684 to 0.32292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.1078 - output_loss_loss: 5.1078 - probabilities_accuracy: 0.4800 - val_loss: 5.2066 - val_output_loss_loss: 5.2066 - val_probabilities_accuracy: 0.3229 - lr: 1.0000e-04\n",
            "Epoch 19/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.1042 - output_loss_loss: 5.1042 - probabilities_accuracy: 0.4906\n",
            "Epoch 00019: val_probabilities_accuracy did not improve from 0.32292\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.1042 - output_loss_loss: 5.1042 - probabilities_accuracy: 0.4906 - val_loss: 5.2004 - val_output_loss_loss: 5.2004 - val_probabilities_accuracy: 0.3229 - lr: 1.0000e-04\n",
            "Epoch 20/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0998 - output_loss_loss: 5.0998 - probabilities_accuracy: 0.5113\n",
            "Epoch 00020: val_probabilities_accuracy did not improve from 0.32292\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.0998 - output_loss_loss: 5.0998 - probabilities_accuracy: 0.5113 - val_loss: 5.2120 - val_output_loss_loss: 5.2120 - val_probabilities_accuracy: 0.1875 - lr: 1.0000e-04\n",
            "Epoch 21/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0777 - output_loss_loss: 5.0777 - probabilities_accuracy: 0.5541\n",
            "Epoch 00021: val_probabilities_accuracy did not improve from 0.32292\n",
            "50/50 [==============================] - 81s 2s/step - loss: 5.0777 - output_loss_loss: 5.0777 - probabilities_accuracy: 0.5541 - val_loss: 5.1726 - val_output_loss_loss: 5.1726 - val_probabilities_accuracy: 0.3026 - lr: 1.0000e-04\n",
            "Epoch 22/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0622 - output_loss_loss: 5.0622 - probabilities_accuracy: 0.5913\n",
            "Epoch 00022: val_probabilities_accuracy improved from 0.32292 to 0.35417, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 5.0622 - output_loss_loss: 5.0622 - probabilities_accuracy: 0.5913 - val_loss: 5.1667 - val_output_loss_loss: 5.1667 - val_probabilities_accuracy: 0.3542 - lr: 1.0000e-04\n",
            "Epoch 23/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0706 - output_loss_loss: 5.0706 - probabilities_accuracy: 0.5900\n",
            "Epoch 00023: val_probabilities_accuracy did not improve from 0.35417\n",
            "50/50 [==============================] - 81s 2s/step - loss: 5.0706 - output_loss_loss: 5.0706 - probabilities_accuracy: 0.5900 - val_loss: 5.1614 - val_output_loss_loss: 5.1614 - val_probabilities_accuracy: 0.3542 - lr: 1.0000e-04\n",
            "Epoch 24/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0620 - output_loss_loss: 5.0620 - probabilities_accuracy: 0.5962\n",
            "Epoch 00024: val_probabilities_accuracy did not improve from 0.35417\n",
            "50/50 [==============================] - 82s 2s/step - loss: 5.0620 - output_loss_loss: 5.0620 - probabilities_accuracy: 0.5962 - val_loss: 5.1547 - val_output_loss_loss: 5.1547 - val_probabilities_accuracy: 0.3229 - lr: 1.0000e-04\n",
            "Epoch 25/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0459 - output_loss_loss: 5.0459 - probabilities_accuracy: 0.6293\n",
            "Epoch 00025: val_probabilities_accuracy improved from 0.35417 to 0.43750, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 84s 2s/step - loss: 5.0459 - output_loss_loss: 5.0459 - probabilities_accuracy: 0.6293 - val_loss: 5.1367 - val_output_loss_loss: 5.1367 - val_probabilities_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 26/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0456 - output_loss_loss: 5.0456 - probabilities_accuracy: 0.6363\n",
            "Epoch 00026: val_probabilities_accuracy did not improve from 0.43750\n",
            "50/50 [==============================] - 81s 2s/step - loss: 5.0456 - output_loss_loss: 5.0456 - probabilities_accuracy: 0.6363 - val_loss: 5.1352 - val_output_loss_loss: 5.1352 - val_probabilities_accuracy: 0.3854 - lr: 1.0000e-04\n",
            "Epoch 27/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0404 - output_loss_loss: 5.0404 - probabilities_accuracy: 0.6431\n",
            "Epoch 00027: val_probabilities_accuracy did not improve from 0.43750\n",
            "50/50 [==============================] - 80s 2s/step - loss: 5.0404 - output_loss_loss: 5.0404 - probabilities_accuracy: 0.6431 - val_loss: 5.1225 - val_output_loss_loss: 5.1225 - val_probabilities_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 28/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0342 - output_loss_loss: 5.0342 - probabilities_accuracy: 0.6463\n",
            "Epoch 00028: val_probabilities_accuracy improved from 0.43750 to 0.55208, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.0342 - output_loss_loss: 5.0342 - probabilities_accuracy: 0.6463 - val_loss: 5.0921 - val_output_loss_loss: 5.0921 - val_probabilities_accuracy: 0.5521 - lr: 1.0000e-04\n",
            "Epoch 29/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0202 - output_loss_loss: 5.0202 - probabilities_accuracy: 0.6882\n",
            "Epoch 00029: val_probabilities_accuracy did not improve from 0.55208\n",
            "50/50 [==============================] - 79s 2s/step - loss: 5.0202 - output_loss_loss: 5.0202 - probabilities_accuracy: 0.6882 - val_loss: 5.1029 - val_output_loss_loss: 5.1029 - val_probabilities_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "Epoch 30/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0185 - output_loss_loss: 5.0185 - probabilities_accuracy: 0.6787\n",
            "Epoch 00030: val_probabilities_accuracy did not improve from 0.55208\n",
            "50/50 [==============================] - 80s 2s/step - loss: 5.0185 - output_loss_loss: 5.0185 - probabilities_accuracy: 0.6787 - val_loss: 5.0683 - val_output_loss_loss: 5.0683 - val_probabilities_accuracy: 0.5417 - lr: 1.0000e-04\n",
            "Epoch 31/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0200 - output_loss_loss: 5.0200 - probabilities_accuracy: 0.6769\n",
            "Epoch 00031: val_probabilities_accuracy did not improve from 0.55208\n",
            "50/50 [==============================] - 80s 2s/step - loss: 5.0200 - output_loss_loss: 5.0200 - probabilities_accuracy: 0.6769 - val_loss: 5.0960 - val_output_loss_loss: 5.0960 - val_probabilities_accuracy: 0.4896 - lr: 1.0000e-04\n",
            "Epoch 32/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0197 - output_loss_loss: 5.0197 - probabilities_accuracy: 0.6775\n",
            "Epoch 00032: val_probabilities_accuracy improved from 0.55208 to 0.57292, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 5.0197 - output_loss_loss: 5.0197 - probabilities_accuracy: 0.6775 - val_loss: 5.0562 - val_output_loss_loss: 5.0562 - val_probabilities_accuracy: 0.5729 - lr: 1.0000e-04\n",
            "Epoch 33/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0007 - output_loss_loss: 5.0007 - probabilities_accuracy: 0.7192\n",
            "Epoch 00033: val_probabilities_accuracy did not improve from 0.57292\n",
            "50/50 [==============================] - 79s 2s/step - loss: 5.0007 - output_loss_loss: 5.0007 - probabilities_accuracy: 0.7192 - val_loss: 5.0744 - val_output_loss_loss: 5.0744 - val_probabilities_accuracy: 0.5104 - lr: 1.0000e-04\n",
            "Epoch 34/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 5.0010 - output_loss_loss: 5.0010 - probabilities_accuracy: 0.7294\n",
            "Epoch 00034: val_probabilities_accuracy improved from 0.57292 to 0.57895, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 81s 2s/step - loss: 5.0010 - output_loss_loss: 5.0010 - probabilities_accuracy: 0.7294 - val_loss: 5.0458 - val_output_loss_loss: 5.0458 - val_probabilities_accuracy: 0.5789 - lr: 1.0000e-04\n",
            "Epoch 35/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9999 - output_loss_loss: 4.9999 - probabilities_accuracy: 0.7231\n",
            "Epoch 00035: val_probabilities_accuracy improved from 0.57895 to 0.61458, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9999 - output_loss_loss: 4.9999 - probabilities_accuracy: 0.7231 - val_loss: 5.0360 - val_output_loss_loss: 5.0360 - val_probabilities_accuracy: 0.6146 - lr: 1.0000e-04\n",
            "Epoch 36/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9935 - output_loss_loss: 4.9935 - probabilities_accuracy: 0.7419\n",
            "Epoch 00036: val_probabilities_accuracy did not improve from 0.61458\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9935 - output_loss_loss: 4.9935 - probabilities_accuracy: 0.7419 - val_loss: 5.0391 - val_output_loss_loss: 5.0391 - val_probabilities_accuracy: 0.5938 - lr: 1.0000e-04\n",
            "Epoch 37/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9845 - output_loss_loss: 4.9845 - probabilities_accuracy: 0.7653\n",
            "Epoch 00037: val_probabilities_accuracy improved from 0.61458 to 0.63542, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9845 - output_loss_loss: 4.9845 - probabilities_accuracy: 0.7653 - val_loss: 5.0185 - val_output_loss_loss: 5.0185 - val_probabilities_accuracy: 0.6354 - lr: 1.0000e-04\n",
            "Epoch 38/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9842 - output_loss_loss: 4.9842 - probabilities_accuracy: 0.7675\n",
            "Epoch 00038: val_probabilities_accuracy improved from 0.63542 to 0.64583, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9842 - output_loss_loss: 4.9842 - probabilities_accuracy: 0.7675 - val_loss: 5.0488 - val_output_loss_loss: 5.0488 - val_probabilities_accuracy: 0.6458 - lr: 1.0000e-04\n",
            "Epoch 39/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9880 - output_loss_loss: 4.9880 - probabilities_accuracy: 0.7563\n",
            "Epoch 00039: val_probabilities_accuracy improved from 0.64583 to 0.67708, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9880 - output_loss_loss: 4.9880 - probabilities_accuracy: 0.7563 - val_loss: 5.0238 - val_output_loss_loss: 5.0238 - val_probabilities_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 40/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9864 - output_loss_loss: 4.9864 - probabilities_accuracy: 0.7500\n",
            "Epoch 00040: val_probabilities_accuracy did not improve from 0.67708\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9864 - output_loss_loss: 4.9864 - probabilities_accuracy: 0.7500 - val_loss: 5.0138 - val_output_loss_loss: 5.0138 - val_probabilities_accuracy: 0.6458 - lr: 1.0000e-04\n",
            "Epoch 41/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9790 - output_loss_loss: 4.9790 - probabilities_accuracy: 0.7691\n",
            "Epoch 00041: val_probabilities_accuracy did not improve from 0.67708\n",
            "50/50 [==============================] - 78s 2s/step - loss: 4.9790 - output_loss_loss: 4.9790 - probabilities_accuracy: 0.7691 - val_loss: 5.0197 - val_output_loss_loss: 5.0197 - val_probabilities_accuracy: 0.6447 - lr: 1.0000e-04\n",
            "Epoch 42/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9791 - output_loss_loss: 4.9791 - probabilities_accuracy: 0.7731\n",
            "Epoch 00042: val_probabilities_accuracy improved from 0.67708 to 0.76042, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9791 - output_loss_loss: 4.9791 - probabilities_accuracy: 0.7731 - val_loss: 4.9810 - val_output_loss_loss: 4.9810 - val_probabilities_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 43/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9725 - output_loss_loss: 4.9725 - probabilities_accuracy: 0.7844\n",
            "Epoch 00043: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9725 - output_loss_loss: 4.9725 - probabilities_accuracy: 0.7844 - val_loss: 5.0172 - val_output_loss_loss: 5.0172 - val_probabilities_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 44/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9695 - output_loss_loss: 4.9695 - probabilities_accuracy: 0.7969\n",
            "Epoch 00044: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9695 - output_loss_loss: 4.9695 - probabilities_accuracy: 0.7969 - val_loss: 4.9990 - val_output_loss_loss: 4.9990 - val_probabilities_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 45/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9614 - output_loss_loss: 4.9614 - probabilities_accuracy: 0.8159\n",
            "Epoch 00045: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9614 - output_loss_loss: 4.9614 - probabilities_accuracy: 0.8159 - val_loss: 4.9830 - val_output_loss_loss: 4.9830 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 46/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9651 - output_loss_loss: 4.9651 - probabilities_accuracy: 0.8044\n",
            "Epoch 00046: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9651 - output_loss_loss: 4.9651 - probabilities_accuracy: 0.8044 - val_loss: 4.9723 - val_output_loss_loss: 4.9723 - val_probabilities_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 47/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9632 - output_loss_loss: 4.9632 - probabilities_accuracy: 0.7969\n",
            "Epoch 00047: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9632 - output_loss_loss: 4.9632 - probabilities_accuracy: 0.7969 - val_loss: 5.0092 - val_output_loss_loss: 5.0092 - val_probabilities_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 48/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9663 - output_loss_loss: 4.9663 - probabilities_accuracy: 0.7956\n",
            "Epoch 00048: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9663 - output_loss_loss: 4.9663 - probabilities_accuracy: 0.7956 - val_loss: 5.0167 - val_output_loss_loss: 5.0167 - val_probabilities_accuracy: 0.5789 - lr: 1.0000e-04\n",
            "Epoch 49/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9564 - output_loss_loss: 4.9564 - probabilities_accuracy: 0.8172\n",
            "Epoch 00049: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9564 - output_loss_loss: 4.9564 - probabilities_accuracy: 0.8172 - val_loss: 4.9859 - val_output_loss_loss: 4.9859 - val_probabilities_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 50/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9549 - output_loss_loss: 4.9549 - probabilities_accuracy: 0.8206\n",
            "Epoch 00050: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9549 - output_loss_loss: 4.9549 - probabilities_accuracy: 0.8206 - val_loss: 4.9792 - val_output_loss_loss: 4.9792 - val_probabilities_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 51/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9533 - output_loss_loss: 4.9533 - probabilities_accuracy: 0.8250\n",
            "Epoch 00051: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9533 - output_loss_loss: 4.9533 - probabilities_accuracy: 0.8250 - val_loss: 4.9634 - val_output_loss_loss: 4.9634 - val_probabilities_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 52/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9572 - output_loss_loss: 4.9572 - probabilities_accuracy: 0.8075\n",
            "Epoch 00052: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9572 - output_loss_loss: 4.9572 - probabilities_accuracy: 0.8075 - val_loss: 5.0061 - val_output_loss_loss: 5.0061 - val_probabilities_accuracy: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 53/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9494 - output_loss_loss: 4.9494 - probabilities_accuracy: 0.8355\n",
            "Epoch 00053: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9494 - output_loss_loss: 4.9494 - probabilities_accuracy: 0.8355 - val_loss: 4.9730 - val_output_loss_loss: 4.9730 - val_probabilities_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 54/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9443 - output_loss_loss: 4.9443 - probabilities_accuracy: 0.8481\n",
            "Epoch 00054: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9443 - output_loss_loss: 4.9443 - probabilities_accuracy: 0.8481 - val_loss: 4.9988 - val_output_loss_loss: 4.9988 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 55/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9469 - output_loss_loss: 4.9469 - probabilities_accuracy: 0.8306\n",
            "Epoch 00055: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9469 - output_loss_loss: 4.9469 - probabilities_accuracy: 0.8306 - val_loss: 4.9807 - val_output_loss_loss: 4.9807 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 56/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9534 - output_loss_loss: 4.9534 - probabilities_accuracy: 0.8206\n",
            "Epoch 00056: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9534 - output_loss_loss: 4.9534 - probabilities_accuracy: 0.8206 - val_loss: 4.9687 - val_output_loss_loss: 4.9687 - val_probabilities_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 57/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9445 - output_loss_loss: 4.9445 - probabilities_accuracy: 0.8387\n",
            "Epoch 00057: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9445 - output_loss_loss: 4.9445 - probabilities_accuracy: 0.8387 - val_loss: 4.9473 - val_output_loss_loss: 4.9473 - val_probabilities_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 58/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9416 - output_loss_loss: 4.9416 - probabilities_accuracy: 0.8450\n",
            "Epoch 00058: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9416 - output_loss_loss: 4.9416 - probabilities_accuracy: 0.8450 - val_loss: 4.9699 - val_output_loss_loss: 4.9699 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 59/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9392 - output_loss_loss: 4.9392 - probabilities_accuracy: 0.8612\n",
            "Epoch 00059: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9392 - output_loss_loss: 4.9392 - probabilities_accuracy: 0.8612 - val_loss: 4.9634 - val_output_loss_loss: 4.9634 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 60/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9400 - output_loss_loss: 4.9400 - probabilities_accuracy: 0.8425\n",
            "Epoch 00060: val_probabilities_accuracy did not improve from 0.76042\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9400 - output_loss_loss: 4.9400 - probabilities_accuracy: 0.8425 - val_loss: 4.9699 - val_output_loss_loss: 4.9699 - val_probabilities_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 61/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9382 - output_loss_loss: 4.9382 - probabilities_accuracy: 0.8590\n",
            "Epoch 00061: val_probabilities_accuracy improved from 0.76042 to 0.80263, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9382 - output_loss_loss: 4.9382 - probabilities_accuracy: 0.8590 - val_loss: 4.9485 - val_output_loss_loss: 4.9485 - val_probabilities_accuracy: 0.8026 - lr: 1.0000e-04\n",
            "Epoch 62/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9292 - output_loss_loss: 4.9292 - probabilities_accuracy: 0.8831\n",
            "Epoch 00062: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9292 - output_loss_loss: 4.9292 - probabilities_accuracy: 0.8831 - val_loss: 4.9583 - val_output_loss_loss: 4.9583 - val_probabilities_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 63/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9378 - output_loss_loss: 4.9378 - probabilities_accuracy: 0.8662\n",
            "Epoch 00063: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9378 - output_loss_loss: 4.9378 - probabilities_accuracy: 0.8662 - val_loss: 4.9717 - val_output_loss_loss: 4.9717 - val_probabilities_accuracy: 0.7083 - lr: 1.0000e-04\n",
            "Epoch 64/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9368 - output_loss_loss: 4.9368 - probabilities_accuracy: 0.8587\n",
            "Epoch 00064: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9368 - output_loss_loss: 4.9368 - probabilities_accuracy: 0.8587 - val_loss: 4.9464 - val_output_loss_loss: 4.9464 - val_probabilities_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 65/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9311 - output_loss_loss: 4.9311 - probabilities_accuracy: 0.8653\n",
            "Epoch 00065: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9311 - output_loss_loss: 4.9311 - probabilities_accuracy: 0.8653 - val_loss: 4.9477 - val_output_loss_loss: 4.9477 - val_probabilities_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 66/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9291 - output_loss_loss: 4.9291 - probabilities_accuracy: 0.8719\n",
            "Epoch 00066: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9291 - output_loss_loss: 4.9291 - probabilities_accuracy: 0.8719 - val_loss: 4.9481 - val_output_loss_loss: 4.9481 - val_probabilities_accuracy: 0.7396 - lr: 1.0000e-04\n",
            "Epoch 67/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9294 - output_loss_loss: 4.9294 - probabilities_accuracy: 0.8700\n",
            "Epoch 00067: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9294 - output_loss_loss: 4.9294 - probabilities_accuracy: 0.8700 - val_loss: 4.9647 - val_output_loss_loss: 4.9647 - val_probabilities_accuracy: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 68/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9323 - output_loss_loss: 4.9323 - probabilities_accuracy: 0.8562\n",
            "Epoch 00068: val_probabilities_accuracy did not improve from 0.80263\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9323 - output_loss_loss: 4.9323 - probabilities_accuracy: 0.8562 - val_loss: 4.9650 - val_output_loss_loss: 4.9650 - val_probabilities_accuracy: 0.7105 - lr: 1.0000e-04\n",
            "Epoch 69/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9253 - output_loss_loss: 4.9253 - probabilities_accuracy: 0.8887\n",
            "Epoch 00069: val_probabilities_accuracy improved from 0.80263 to 0.84375, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9253 - output_loss_loss: 4.9253 - probabilities_accuracy: 0.8887 - val_loss: 4.9305 - val_output_loss_loss: 4.9305 - val_probabilities_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 70/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9256 - output_loss_loss: 4.9256 - probabilities_accuracy: 0.8856\n",
            "Epoch 00070: val_probabilities_accuracy improved from 0.84375 to 0.85417, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9256 - output_loss_loss: 4.9256 - probabilities_accuracy: 0.8856 - val_loss: 4.9317 - val_output_loss_loss: 4.9317 - val_probabilities_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 71/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9270 - output_loss_loss: 4.9270 - probabilities_accuracy: 0.8763\n",
            "Epoch 00071: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9270 - output_loss_loss: 4.9270 - probabilities_accuracy: 0.8763 - val_loss: 4.9492 - val_output_loss_loss: 4.9492 - val_probabilities_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 72/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9218 - output_loss_loss: 4.9218 - probabilities_accuracy: 0.8888\n",
            "Epoch 00072: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9218 - output_loss_loss: 4.9218 - probabilities_accuracy: 0.8888 - val_loss: 4.9636 - val_output_loss_loss: 4.9636 - val_probabilities_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 73/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9155 - output_loss_loss: 4.9155 - probabilities_accuracy: 0.9077\n",
            "Epoch 00073: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 79s 2s/step - loss: 4.9155 - output_loss_loss: 4.9155 - probabilities_accuracy: 0.9077 - val_loss: 4.9478 - val_output_loss_loss: 4.9478 - val_probabilities_accuracy: 0.7604 - lr: 1.0000e-04\n",
            "Epoch 74/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9236 - output_loss_loss: 4.9236 - probabilities_accuracy: 0.8869\n",
            "Epoch 00074: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9236 - output_loss_loss: 4.9236 - probabilities_accuracy: 0.8869 - val_loss: 4.9501 - val_output_loss_loss: 4.9501 - val_probabilities_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 75/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9209 - output_loss_loss: 4.9209 - probabilities_accuracy: 0.8913\n",
            "Epoch 00075: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9209 - output_loss_loss: 4.9209 - probabilities_accuracy: 0.8913 - val_loss: 4.9580 - val_output_loss_loss: 4.9580 - val_probabilities_accuracy: 0.7763 - lr: 1.0000e-04\n",
            "Epoch 76/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9224 - output_loss_loss: 4.9224 - probabilities_accuracy: 0.8863\n",
            "Epoch 00076: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9224 - output_loss_loss: 4.9224 - probabilities_accuracy: 0.8863 - val_loss: 4.9423 - val_output_loss_loss: 4.9423 - val_probabilities_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 77/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9178 - output_loss_loss: 4.9178 - probabilities_accuracy: 0.8982\n",
            "Epoch 00077: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9178 - output_loss_loss: 4.9178 - probabilities_accuracy: 0.8982 - val_loss: 4.9547 - val_output_loss_loss: 4.9547 - val_probabilities_accuracy: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 78/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9195 - output_loss_loss: 4.9195 - probabilities_accuracy: 0.8969\n",
            "Epoch 00078: val_probabilities_accuracy did not improve from 0.85417\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9195 - output_loss_loss: 4.9195 - probabilities_accuracy: 0.8969 - val_loss: 4.9374 - val_output_loss_loss: 4.9374 - val_probabilities_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 79/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9175 - output_loss_loss: 4.9175 - probabilities_accuracy: 0.8975\n",
            "Epoch 00079: val_probabilities_accuracy improved from 0.85417 to 0.86458, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.9175 - output_loss_loss: 4.9175 - probabilities_accuracy: 0.8975 - val_loss: 4.9225 - val_output_loss_loss: 4.9225 - val_probabilities_accuracy: 0.8646 - lr: 1.0000e-04\n",
            "Epoch 80/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9190 - output_loss_loss: 4.9190 - probabilities_accuracy: 0.8988\n",
            "Epoch 00080: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9190 - output_loss_loss: 4.9190 - probabilities_accuracy: 0.8988 - val_loss: 4.9264 - val_output_loss_loss: 4.9264 - val_probabilities_accuracy: 0.7917 - lr: 1.0000e-04\n",
            "Epoch 81/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9128 - output_loss_loss: 4.9128 - probabilities_accuracy: 0.9051\n",
            "Epoch 00081: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 80s 2s/step - loss: 4.9128 - output_loss_loss: 4.9128 - probabilities_accuracy: 0.9051 - val_loss: 4.9439 - val_output_loss_loss: 4.9439 - val_probabilities_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 82/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9123 - output_loss_loss: 4.9123 - probabilities_accuracy: 0.9119\n",
            "Epoch 00082: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9123 - output_loss_loss: 4.9123 - probabilities_accuracy: 0.9119 - val_loss: 4.9267 - val_output_loss_loss: 4.9267 - val_probabilities_accuracy: 0.8542 - lr: 1.0000e-04\n",
            "Epoch 83/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9125 - output_loss_loss: 4.9125 - probabilities_accuracy: 0.9056\n",
            "Epoch 00083: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9125 - output_loss_loss: 4.9125 - probabilities_accuracy: 0.9056 - val_loss: 4.9626 - val_output_loss_loss: 4.9626 - val_probabilities_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 84/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9148 - output_loss_loss: 4.9148 - probabilities_accuracy: 0.9000\n",
            "Epoch 00084: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9148 - output_loss_loss: 4.9148 - probabilities_accuracy: 0.9000 - val_loss: 4.9311 - val_output_loss_loss: 4.9311 - val_probabilities_accuracy: 0.8021 - lr: 1.0000e-04\n",
            "Epoch 85/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9116 - output_loss_loss: 4.9116 - probabilities_accuracy: 0.9064\n",
            "Epoch 00085: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9116 - output_loss_loss: 4.9116 - probabilities_accuracy: 0.9064 - val_loss: 4.9260 - val_output_loss_loss: 4.9260 - val_probabilities_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 86/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9063 - output_loss_loss: 4.9063 - probabilities_accuracy: 0.9312\n",
            "Epoch 00086: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9063 - output_loss_loss: 4.9063 - probabilities_accuracy: 0.9312 - val_loss: 4.9265 - val_output_loss_loss: 4.9265 - val_probabilities_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Epoch 87/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9097 - output_loss_loss: 4.9097 - probabilities_accuracy: 0.9106\n",
            "Epoch 00087: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9097 - output_loss_loss: 4.9097 - probabilities_accuracy: 0.9106 - val_loss: 4.9517 - val_output_loss_loss: 4.9517 - val_probabilities_accuracy: 0.7812 - lr: 1.0000e-04\n",
            "Epoch 88/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9105 - output_loss_loss: 4.9105 - probabilities_accuracy: 0.9081\n",
            "Epoch 00088: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9105 - output_loss_loss: 4.9105 - probabilities_accuracy: 0.9081 - val_loss: 4.9609 - val_output_loss_loss: 4.9609 - val_probabilities_accuracy: 0.6842 - lr: 1.0000e-04\n",
            "Epoch 89/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9086 - output_loss_loss: 4.9086 - probabilities_accuracy: 0.9197\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 00089: val_probabilities_accuracy did not improve from 0.86458\n",
            "50/50 [==============================] - 81s 2s/step - loss: 4.9086 - output_loss_loss: 4.9086 - probabilities_accuracy: 0.9197 - val_loss: 4.9235 - val_output_loss_loss: 4.9235 - val_probabilities_accuracy: 0.8125 - lr: 1.0000e-04\n",
            "Epoch 90/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9037 - output_loss_loss: 4.9037 - probabilities_accuracy: 0.9362\n",
            "Epoch 00090: val_probabilities_accuracy improved from 0.86458 to 0.89583, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.9037 - output_loss_loss: 4.9037 - probabilities_accuracy: 0.9362 - val_loss: 4.9066 - val_output_loss_loss: 4.9066 - val_probabilities_accuracy: 0.8958 - lr: 1.0000e-05\n",
            "Epoch 91/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9041 - output_loss_loss: 4.9041 - probabilities_accuracy: 0.9350\n",
            "Epoch 00091: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9041 - output_loss_loss: 4.9041 - probabilities_accuracy: 0.9350 - val_loss: 4.9311 - val_output_loss_loss: 4.9311 - val_probabilities_accuracy: 0.7812 - lr: 1.0000e-05\n",
            "Epoch 92/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9040 - output_loss_loss: 4.9040 - probabilities_accuracy: 0.9319\n",
            "Epoch 00092: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9040 - output_loss_loss: 4.9040 - probabilities_accuracy: 0.9319 - val_loss: 4.9225 - val_output_loss_loss: 4.9225 - val_probabilities_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 93/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9033 - output_loss_loss: 4.9033 - probabilities_accuracy: 0.9336\n",
            "Epoch 00093: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9033 - output_loss_loss: 4.9033 - probabilities_accuracy: 0.9336 - val_loss: 4.9514 - val_output_loss_loss: 4.9514 - val_probabilities_accuracy: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 94/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9010 - output_loss_loss: 4.9010 - probabilities_accuracy: 0.9413\n",
            "Epoch 00094: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.9010 - output_loss_loss: 4.9010 - probabilities_accuracy: 0.9413 - val_loss: 4.9031 - val_output_loss_loss: 4.9031 - val_probabilities_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 95/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9009 - output_loss_loss: 4.9009 - probabilities_accuracy: 0.9356\n",
            "Epoch 00095: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.9009 - output_loss_loss: 4.9009 - probabilities_accuracy: 0.9356 - val_loss: 4.9659 - val_output_loss_loss: 4.9659 - val_probabilities_accuracy: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 96/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8999 - output_loss_loss: 4.8999 - probabilities_accuracy: 0.9425\n",
            "Epoch 00096: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.8999 - output_loss_loss: 4.8999 - probabilities_accuracy: 0.9425 - val_loss: 4.9194 - val_output_loss_loss: 4.9194 - val_probabilities_accuracy: 0.8646 - lr: 1.0000e-05\n",
            "Epoch 97/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8989 - output_loss_loss: 4.8989 - probabilities_accuracy: 0.9374\n",
            "Epoch 00097: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8989 - output_loss_loss: 4.8989 - probabilities_accuracy: 0.9374 - val_loss: 4.9215 - val_output_loss_loss: 4.9215 - val_probabilities_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 98/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8950 - output_loss_loss: 4.8950 - probabilities_accuracy: 0.9563\n",
            "Epoch 00098: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8950 - output_loss_loss: 4.8950 - probabilities_accuracy: 0.9563 - val_loss: 4.9209 - val_output_loss_loss: 4.9209 - val_probabilities_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 99/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.9020 - output_loss_loss: 4.9020 - probabilities_accuracy: 0.9362\n",
            "Epoch 00099: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.9020 - output_loss_loss: 4.9020 - probabilities_accuracy: 0.9362 - val_loss: 4.9405 - val_output_loss_loss: 4.9405 - val_probabilities_accuracy: 0.8021 - lr: 1.0000e-05\n",
            "Epoch 100/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8978 - output_loss_loss: 4.8978 - probabilities_accuracy: 0.9388\n",
            "Epoch 00100: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8978 - output_loss_loss: 4.8978 - probabilities_accuracy: 0.9388 - val_loss: 4.9308 - val_output_loss_loss: 4.9308 - val_probabilities_accuracy: 0.8438 - lr: 1.0000e-05\n",
            "Epoch 101/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8988 - output_loss_loss: 4.8988 - probabilities_accuracy: 0.9311\n",
            "Epoch 00101: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8988 - output_loss_loss: 4.8988 - probabilities_accuracy: 0.9311 - val_loss: 4.9369 - val_output_loss_loss: 4.9369 - val_probabilities_accuracy: 0.7917 - lr: 1.0000e-05\n",
            "Epoch 102/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8983 - output_loss_loss: 4.8983 - probabilities_accuracy: 0.9388\n",
            "Epoch 00102: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8983 - output_loss_loss: 4.8983 - probabilities_accuracy: 0.9388 - val_loss: 4.9629 - val_output_loss_loss: 4.9629 - val_probabilities_accuracy: 0.7237 - lr: 1.0000e-05\n",
            "Epoch 103/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8999 - output_loss_loss: 4.8999 - probabilities_accuracy: 0.9406\n",
            "Epoch 00103: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8999 - output_loss_loss: 4.8999 - probabilities_accuracy: 0.9406 - val_loss: 4.9544 - val_output_loss_loss: 4.9544 - val_probabilities_accuracy: 0.7500 - lr: 1.0000e-05\n",
            "Epoch 104/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8978 - output_loss_loss: 4.8978 - probabilities_accuracy: 0.9438\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "\n",
            "Epoch 00104: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8978 - output_loss_loss: 4.8978 - probabilities_accuracy: 0.9438 - val_loss: 4.9311 - val_output_loss_loss: 4.9311 - val_probabilities_accuracy: 0.7604 - lr: 1.0000e-05\n",
            "Epoch 105/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8977 - output_loss_loss: 4.8977 - probabilities_accuracy: 0.9380\n",
            "Epoch 00105: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8977 - output_loss_loss: 4.8977 - probabilities_accuracy: 0.9380 - val_loss: 4.9002 - val_output_loss_loss: 4.9002 - val_probabilities_accuracy: 0.8750 - lr: 1.0000e-06\n",
            "Epoch 106/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8986 - output_loss_loss: 4.8986 - probabilities_accuracy: 0.9356\n",
            "Epoch 00106: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8986 - output_loss_loss: 4.8986 - probabilities_accuracy: 0.9356 - val_loss: 4.9345 - val_output_loss_loss: 4.9345 - val_probabilities_accuracy: 0.8229 - lr: 1.0000e-06\n",
            "Epoch 107/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8944 - output_loss_loss: 4.8944 - probabilities_accuracy: 0.9525\n",
            "Epoch 00107: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8944 - output_loss_loss: 4.8944 - probabilities_accuracy: 0.9525 - val_loss: 4.9096 - val_output_loss_loss: 4.9096 - val_probabilities_accuracy: 0.8854 - lr: 1.0000e-06\n",
            "Epoch 108/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8950 - output_loss_loss: 4.8950 - probabilities_accuracy: 0.9469\n",
            "Epoch 00108: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.8950 - output_loss_loss: 4.8950 - probabilities_accuracy: 0.9469 - val_loss: 4.8981 - val_output_loss_loss: 4.8981 - val_probabilities_accuracy: 0.8958 - lr: 1.0000e-06\n",
            "Epoch 109/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8974 - output_loss_loss: 4.8974 - probabilities_accuracy: 0.9437\n",
            "Epoch 00109: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 82s 2s/step - loss: 4.8974 - output_loss_loss: 4.8974 - probabilities_accuracy: 0.9437 - val_loss: 4.9390 - val_output_loss_loss: 4.9390 - val_probabilities_accuracy: 0.7917 - lr: 1.0000e-06\n",
            "Epoch 110/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8995 - output_loss_loss: 4.8995 - probabilities_accuracy: 0.9356\n",
            "Epoch 00110: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8995 - output_loss_loss: 4.8995 - probabilities_accuracy: 0.9356 - val_loss: 4.9515 - val_output_loss_loss: 4.9515 - val_probabilities_accuracy: 0.7917 - lr: 1.0000e-06\n",
            "Epoch 111/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8992 - output_loss_loss: 4.8992 - probabilities_accuracy: 0.9450\n",
            "Epoch 00111: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8992 - output_loss_loss: 4.8992 - probabilities_accuracy: 0.9450 - val_loss: 4.9299 - val_output_loss_loss: 4.9299 - val_probabilities_accuracy: 0.8229 - lr: 1.0000e-06\n",
            "Epoch 112/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8931 - output_loss_loss: 4.8931 - probabilities_accuracy: 0.9538\n",
            "Epoch 00112: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8931 - output_loss_loss: 4.8931 - probabilities_accuracy: 0.9538 - val_loss: 4.9210 - val_output_loss_loss: 4.9210 - val_probabilities_accuracy: 0.8333 - lr: 1.0000e-06\n",
            "Epoch 113/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8953 - output_loss_loss: 4.8953 - probabilities_accuracy: 0.9475\n",
            "Epoch 00113: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 83s 2s/step - loss: 4.8953 - output_loss_loss: 4.8953 - probabilities_accuracy: 0.9475 - val_loss: 4.9269 - val_output_loss_loss: 4.9269 - val_probabilities_accuracy: 0.8125 - lr: 1.0000e-06\n",
            "Epoch 114/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8965 - output_loss_loss: 4.8965 - probabilities_accuracy: 0.9506\n",
            "Epoch 00114: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8965 - output_loss_loss: 4.8965 - probabilities_accuracy: 0.9506 - val_loss: 4.8990 - val_output_loss_loss: 4.8990 - val_probabilities_accuracy: 0.8542 - lr: 1.0000e-06\n",
            "Epoch 115/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8977 - output_loss_loss: 4.8977 - probabilities_accuracy: 0.9431\n",
            "Epoch 00115: val_probabilities_accuracy did not improve from 0.89583\n",
            "50/50 [==============================] - 84s 2s/step - loss: 4.8977 - output_loss_loss: 4.8977 - probabilities_accuracy: 0.9431 - val_loss: 4.9428 - val_output_loss_loss: 4.9428 - val_probabilities_accuracy: 0.8158 - lr: 1.0000e-06\n",
            "Epoch 116/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8972 - output_loss_loss: 4.8972 - probabilities_accuracy: 0.9413\n",
            "Epoch 00116: val_probabilities_accuracy improved from 0.89583 to 0.90625, saving model to best_model_weights.hdf5\n",
            "50/50 [==============================] - 88s 2s/step - loss: 4.8972 - output_loss_loss: 4.8972 - probabilities_accuracy: 0.9413 - val_loss: 4.8970 - val_output_loss_loss: 4.8970 - val_probabilities_accuracy: 0.9062 - lr: 1.0000e-06\n",
            "Epoch 117/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8970 - output_loss_loss: 4.8970 - probabilities_accuracy: 0.9450\n",
            "Epoch 00117: val_probabilities_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.8970 - output_loss_loss: 4.8970 - probabilities_accuracy: 0.9450 - val_loss: 4.9392 - val_output_loss_loss: 4.9392 - val_probabilities_accuracy: 0.7812 - lr: 1.0000e-06\n",
            "Epoch 118/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8983 - output_loss_loss: 4.8983 - probabilities_accuracy: 0.9388\n",
            "Epoch 00118: val_probabilities_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.8983 - output_loss_loss: 4.8983 - probabilities_accuracy: 0.9388 - val_loss: 4.9096 - val_output_loss_loss: 4.9096 - val_probabilities_accuracy: 0.8854 - lr: 1.0000e-06\n",
            "Epoch 119/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8993 - output_loss_loss: 4.8993 - probabilities_accuracy: 0.9394\n",
            "Epoch 00119: val_probabilities_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.8993 - output_loss_loss: 4.8993 - probabilities_accuracy: 0.9394 - val_loss: 4.9457 - val_output_loss_loss: 4.9457 - val_probabilities_accuracy: 0.7500 - lr: 1.0000e-06\n",
            "Epoch 120/120\n",
            "50/50 [==============================] - ETA: 0s - loss: 4.8937 - output_loss_loss: 4.8937 - probabilities_accuracy: 0.9519\n",
            "Epoch 00120: val_probabilities_accuracy did not improve from 0.90625\n",
            "50/50 [==============================] - 85s 2s/step - loss: 4.8937 - output_loss_loss: 4.8937 - probabilities_accuracy: 0.9519 - val_loss: 4.9149 - val_output_loss_loss: 4.9149 - val_probabilities_accuracy: 0.8542 - lr: 1.0000e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZTPuGY8rWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "aac850d4-a084-46f1-a120-cbfd81548e33"
      },
      "source": [
        "# Visualise accuracy history\n",
        "plt.plot(history.history['probabilities_accuracy'])\n",
        "plt.plot(history.history['val_probabilities_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Visualise loss history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUVfrA8e+ZZNJ7IRVI6L2GjgoWmr1h74q67uq6a1n96bq667prX7u4Yu8Fy4qIKIg0IfQOoaYQUiC9Z87vjzNDJiEhbSaQ5P08D88k994590zcve+c856itNYIIYTovCwnugJCCCFOLAkEQgjRyUkgEEKITk4CgRBCdHISCIQQopOTQCCEEJ2cBAIhmkgp9bZS6h9NvHafUurM1pYjRFuQQCCEEJ2cBAIhhOjkJBCIDsXeJXOvUmqjUqpYKfWmUipKKfW9UqpQKbVQKRXqdP15SqktSqk8pdRipVR/p3PDlVJr7e/7BPCpc69zlFLr7e9drpQa0sI636KUSlFKHVZKfaOUirUfV0qp55RSWUqpAqXUJqXUIPu5GUqprfa6pSul7mnRH0wIJBCIjuli4CygD3Au8D3wIBCJ+d/8nQBKqT7AR8Af7efmAd8qpbyUUl7AV8B7QBjwmb1c7O8dDswBbgXCgdeBb5RS3s2pqFLqdOAJYCYQA+wHPrafngKcav8cwfZrcu3n3gRu1VoHAoOAn5tzXyGcSSAQHdGLWutDWut04FfgN631Oq11GTAXGG6/7jLgO631j1rrSuBpwBcYD4wFrMDzWutKrfXnwGqne8wCXtda/6a1rtZavwOU29/XHFcBc7TWa7XW5cADwDilVAJQCQQC/QCltd6mtT5of18lMEApFaS1PqK1XtvM+wpxlAQC0REdcvq5tJ7fA+w/x2K+gQOgtbYBqUCc/Vy6rr0q436nn7sDf7Z3C+UppfKArvb3NUfdOhRhvvXHaa1/Bl4CXgaylFKzlVJB9ksvBmYA+5VSvyilxjXzvkIcJYFAdGYZmAc6YPrkMQ/zdOAgEGc/5tDN6edU4HGtdYjTPz+t9UetrIM/pqspHUBr/YLWeiQwANNFdK/9+Gqt9flAF0wX1qfNvK8QR0kgEJ3Zp8DZSqkzlFJW4M+Y7p3lwAqgCrhTKWVVSl0EjHZ67xvAbUqpMfakrr9S6mylVGAz6/ARcINSapg9v/BPTFfWPqXUKHv5VqAYKANs9hzGVUqpYHuXVgFga8XfQXRyEghEp6W13gFcDbwI5GASy+dqrSu01hXARcD1wGFMPuFLp/cmA7dgum6OACn2a5tbh4XAw8AXmFZIT+By++kgTMA5guk+ygWesp+7BtinlCoAbsPkGoRoESUb0wghROcmLQIhhOjkJBAIIUQnJ4FACCE6ObcGAvt0/032afjJx7lulFKqSil1iTvrI4QQ4liebXCPyVrrnIZOKqU8gH8DC5pSWEREhE5ISHBR1YQQonNYs2ZNjtY6sr5zbREIGvMHzNC5UU25OCEhgeTkBhsXQggh6qGU2t/QOXfnCDSwQCm1Rik1q+5JpVQccCHw6vEKUUrNUkolK6WSs7Oz3VRVIYTonNwdCCZqrUcA04E7lFKn1jn/PHC/fY2XBmmtZ2utk7TWSZGR9bZshBBCtJBbu4bsqz+itc5SSs3FTNFf4nRJEvCxfTmXCGCGUqpKa/2VO+slhBCihtsCgX3xLIvWutD+8xTgMedrtNaJTte/DfyvJUGgsrKStLQ0ysrKWlnrk5+Pjw/x8fFYrdYTXRUhRAfhzhZBFDDX/m3fE/hQaz1fKXUbgNb6NVfdKC0tjcDAQBISEqi9WGTHorUmNzeXtLQ0EhMTG3+DEEI0gdsCgdZ6DzC0nuP1BgCt9fUtvVdZWVmHDwIASinCw8ORhLkQwpU6zMzijh4EHDrL5xRCtJ0OEwgaU1ZZzcG8Umw2WW1VCCGcdZpAUFlRjrU4g5KKSpeXnZeXxyuvvNLs982YMYO8vDyX10cIIZqj0wQCP1VOhCqAwkyXl91QIKiqqjru++bNm0dISIjL6yOEEM1xMiwx0SY8/EIpyM8lsDIXysPAO6DxNzXRX/7yF3bv3s2wYcOwWq34+PgQGhrK9u3b2blzJxdccAGpqamUlZVx1113MWuWmWTtWC6jqKiI6dOnM3HiRJYvX05cXBxff/01vr6+LqujEEI0pMMFgke/3cLWjIJ6z1VUVWO1laFULlj9gKYlXgfEBvHIuQMbPP+vf/2LzZs3s379ehYvXszZZ5/N5s2bjw7xnDNnDmFhYZSWljJq1CguvvhiwsPDa5Wxa9cuPvroI9544w1mzpzJF198wdVXX920Dy2EEK3QabqGADwsFsq0FbSGqgq33Wf06NG1xvm/8MILDB06lLFjx5KamsquXbuOeU9iYiLDhg0DYOTIkezbt89t9RNCCGcdrkVwvG/uVdU2th4soLfXYXyrCyFqMFhcHwv9/f2P/rx48WIWLlzIihUr8PPzY9KkSfXOgPb29j76s4eHB6WlpS6vlxBC1KdTtQg8PSz4WD3IJwC0DSoKa05WlkFFcYvKDQwMpLCwsN5z+fn5hIaG4ufnx/bt21m5cmWL7iGEEO7S4VoEjQnw9iS32IsoiweqNA98gk1X0ZG9YKuCqEHQzElb4eHhTJgwgUGDBuHr60tUVNTRc9OmTeO1116jf//+9O3bl7Fjx7r6IwkhRKt0ukDg7+VBThFUeQVhLcs3LYOyAqiyd9dUl4OnT7PL/fDDD+s97u3tzffff1/vOUceICIigs2bNx89fs899zT7/kII0VKdqmsIwN/bxL5iFQC6GsqLoOgQKA9zQQu7h4QQor3qdIHAkSfIqfRCKwsUpENlCQTFmGBQUXSiqyiEEG2q0wUCgIgAb0oqbVR4BpouIYsV/MLBKwDKpUUghOhcOmUgCPWz4uflSValfeZuQCQoC3j7mxxBtX09Iq3NPyGE6MA6ZSBQShEX4kOezZdcrzjwt++D7GVfdsKRJyg8CFlbwVZ9YioqhBBtoFMGAgBfL0/CArzJKPOiuMJmDlp9AYvJE1SWQVEWVFdAyeETWlchhHCnThsIAKKCvPHy9GB/bgnlVdWme8jLzwSCgnTzu9XXjCrStgbLaeky1ADPP/88JSUlLf0IQgjRap06EHhaLCSE+6HR7MspoaraZrqHKkuhvAACoyEwBmyVUHqkwXIkEAgh2rNON6GsLm+rB93D/dmbU0zakVISAuzrBHl4g38EoMDTFwoPgW9YvbOOnZehPuuss+jSpQuffvop5eXlXHjhhTz66KMUFxczc+ZM0tLSqK6u5uGHH+bQoUNkZGQwefJkIiIiWLRoUdt+eCGEoCMGgu//ApmbmvWWAKBvtY2KKhs2Lw8sVaXg6QXK/ueJ6A0jr4OyfPA9diMZ52WoFyxYwOeff86qVavQWnPeeeexZMkSsrOziY2N5bvvvgPMGkTBwcE8++yzLFq0iIiIiNZ+ciGEaJFO3TXkzNNivulX2bTZq0A5xUhPb/DwsucKjj+cdMGCBSxYsIDhw4czYsQItm/fzq5duxg8eDA//vgj999/P7/++ivBwcHu/DhCCNFkHa9FMP1fLXqbBcjMKsKmNX2iAo+9oDgb8tPM0NLj7G6mteaBBx7g1ltvPebc2rVrmTdvHg899BBnnHEGf/3rX1tUVyGEcCVpETgJ8bNSVllNWWU98wZ8w8wSFEVZx5xyXoZ66tSpzJkzh6Iis1RFeno6WVlZZGRk4Ofnx9VXX829997L2rVrj3mvEEKcCB2vRdAKwb5WDuaVkVdSQXRwnf2CLR5m4llRppljYK1ZodR5Gerp06dz5ZVXMm7cOAACAgJ4//33SUlJ4d5778VisWC1Wnn11VcBmDVrFtOmTSM2NlaSxUKIE0LpdraEQlJSkk5OTq51bNu2bfTv398l5e/NKaa8spq+0YGouiOEqivh0BbwC4OQbi65X0u48vMKIToHpdQarXVSfeeka6iOEF8rFdU2Sirq6R7ysJogUHJYlp0QQnQYEgjqCPK1YlGKw8UNbG7vEwJo2bdACNFhdJhA4KouLg+LItTPSl5ppZlpXJeXn3mtPDGzgdtbV54Q4uTXIQKBj48Pubm5LntIhgd4o7XmcEk9rQKLp9nK8gS0CLTW5Obm4uPT/K00hRCiIR1i1FB8fDxpaWlkZ2e7rMy8wnJy0zQ5QT7HripRcti0CLLqCRRVZZhlKbxdVhdnPj4+xMfHu6VsIUTn5NZAoJTaBxQC1UBV3Yy1Uup84O+ADagC/qi1Xtrc+1itVhITE1tfYSd7Nx3kdx+s5b/XJnFm/6jaJ9e+C/P/AL9PNstPOGz+Ar68GSL6wB2/ubQ+QgjhLm3RNTRZaz2sgWFLPwFDtdbDgBuB/7ZBfZrkrAFRRAV5886KfceejB9tXlNX1Rzb8T18OcssVpe9XfYwEEK0Gyc0R6C1LtI1Hfv+wEmTCbV6WLhmbHd+3ZXDloz82icj+oBPMKTZA0H6Gvj0WogeApfMMcfSVrdthYUQooXcHQg0sEAptUYpNau+C5RSFyqltgPfYVoF9V0zSymVrJRKdmUeoDHXjEsg0NuTlxel1D5hsUBcEqSuBpsNvvuzWYLi6i+gx2lmKYpU6RoSQrQP7g4EE7XWI4DpwB1KqVPrXqC1nqu17gdcgMkXHENrPVtrnaS1ToqMjHRvjZ0E+1q5bnwC32/OZNehOusBxY8y+xmveh0y1sGUv5vJZl7+EDMEDkggEEK0D24NBFrrdPtrFjAXGH2ca5cAPZRSJ9XC/DdOTMTX6nFsq6DrKEDDD/8HXcfA4Eudzo013UXVlW1aVyGEaAm3BQKllL9SKtDxMzAF2Fznml7KvqCPUmoE4A3kuqtOLRHm78XVY7vzzYYM9uU4zR2Is+e+tQ2mP1l757JuY6CqFA5ubNvKCiFEC7izRRAFLFVKbQBWAd9precrpW5TSt1mv+ZiYLNSaj3wMnCZPgmnzt58SiJWDwuvLHZqFfiGQO+pMP4PEDus9hu6jjWvqSvbrpJCCNFCHWL10bbwt2+28P7K/fxy32TiQnwbf8PzgyFmGFz2nvsrJ4QQjZDVR11g1qk9UApm/7K7aW/oOtaMHGpngVYI0flIIGii2BBfLhoez0erU8kqLGv8Dd3GmD2O8/a7v3JCCNEKEgia4fZJPamqtvHmr3sbv7jbePO6d4l7KyWEEK0kgaAZEiL8OXdoLO+t3E9JRdXxL+7SH4LiYecPbVM5IYRoIQkEzXTe0FhKKqrZklFw/AuVgj5TYfciqCpvm8oJIUQLSCBopsHxwQBsSM1r/OI+06CyGPY1e0FVIYRoMxIImqlLoA8xwT5sSs9v/OLEU8DTV7qHhBAnNQkELTAkPpiNaU0IBFZf6DEJds6XYaRCiJOWBIIWGBIfwt6cYvJLm7CWUJ+pZghp9nb3V0wIIVpAAkELDLHnCTY1pVXQZ6p53TnfjTUSQoiWk0DQAoPjTCDYmN6EhHFQrNmwZvt3bq6VEEK0jASCFgjx86J7uB8bU5vQIgAYeoXZsWzPL+6tmBBCtIAEghYaEh/CxrQmtAgAkm40k8sW/k2SxkKIk44EghYaEhdMRn4Z2YVNmCxm9YHJD0DGWtj2jfsrJ4QQzSCBoIWOJoybkicA0z0U2Q9++jtUN7I8hRBCtCEJBC00MC4YpWBDU/MEFg8446+Quws+uQoObXFvBYUQookkELRQgLcnQ+JDmLsunYoqW9Pe1HcGnPk32L8cXp0Ac2+DiuLG3iWEEG4lgaAV/nhmbw4cLuGjVQea9galYOLdcNcGmHAXbPwE3j4HirLdW1EhhDgOCQStMKlPJGN7hPHiz7soKm9Gv79fGJz1KFz2AWRtgzfPhMN73FdRIYQ4DgkEraCU4v5p/cgpquC/v7bgQd5vBlz/PyjLh0+uleWqhRAnhASCVhreLZTpg6J5Y8keDhdXNL+A+CS44FU4tAkWP+H6CgohRCMkELjA3Wf1obiimk+TU1tWQN/pMOI6WPo87F/h2soJIUQjJBC4QJ+oQEYnhvHhbwew2Vo4c3jqPyG0O8ydJV1EQog2JYHARa4a040Dh0tYmpLTsgK8A2DKPyDvAByQVoEQou1IIHCRaYOiCff34v2V+1teSI/JYLHC7p9dVzEhhGiEBAIX8fb04NKkrvy0PYuD+aUtLCQAuo4xG94LIUQbkUDgQleO7oZNaz5e1cKkMUDPyZC5USaZCSHajAQCF+oW7scpvSP5LDmV6pYmjXuebl73LHZZvYQQ4ngkELjYZUldycgvY1lLk8YxQ8E3TPIEQog2I4HAxc4c0IUQP2vL5xRYPKDHJBMI6m5is+tH2LWwtVUUQohaJBC4mLenBxcMi2PBlkPklbRgpjGYPEFRplmHyKE4Bz67AX582DUVFUIIOwkEbjAzqSsV1Ta+Xp/RsgJ6TDavu3+qOfbLk1BRCLkpsrGNEMKl3BoIlFL7lFKblFLrlVLJ9Zy/Sim10X7NcqXUUHfWp60MiA1iUFxQy7uHQrpC9BBY8jRkrDcrkybPgYBoqK6AvFbMVRBCiDraokUwWWs9TGudVM+5vcBpWuvBwN+B2W1QnzYxM6krWzIK2JpR0MIC3gXvQHj3PPj692DxhLOfNueyd7iuokKITu+Edg1prZdrrY/Yf10JxJ/I+rjSWQOiAEjef7hlBYQlwvXfgU8w7F8G4+6AxFPNuRwJBEII13F3INDAAqXUGqXUrEauvQn4vr4TSqlZSqlkpVRydnb7mGgVHeRDqJ+15S0CMIvQXT8PJj1gdjbzCTbdQ9k7XVdRIUSn5+nm8idqrdOVUl2AH5VS27XWS+pepJSajAkEE+srRGs9G3u3UVJSUgtnarUtpRT9Y4LYdrAVgQBMvmDSX2p+j+wjLQIhhEu5tUWgtU63v2YBc4HRda9RSg0B/gucr7XOdWd92tqAmCC2ZxZSVd3Eze2bIqKvaRHUnWMghBAt5LZAoJTyV0oFOn4GpgCb61zTDfgSuEZr3eH6O/rHBFFeZWNfbrHrCo3sa4aRFh50XZlCiE7NnS2CKGCpUmoDsAr4Tms9Xyl1m1LqNvs1fwXCgVcaGmLanvWPCQJg68FC1xUa0ce85nS4uCmEOEHcliPQWu8BjpkXoLV+zennm4Gb3VWHE61XlwCsHoqtGQWcNzTWNYU6AkH2TrMUhRBCtJLMLHYjL08LvboEtj5h7CwwGryDJGEshHAZCQRu1j8mkK2uDARKmVaBTCoTQriIBAI3GxATRHZhOTlFLtyQPrKv5AiEEC4jgcDNBtgTxi7tHoroA0WHoDTPdWUKITotCQRudnTkUGtmGNcV2de8Zm11XZlCiE5LAoGbhfp7ERPs49oWQdxI8AqAr26HI/tcV64QolOSQNAGBsYGsWhHNp+vSWv5XsbOArrAtV+brqE50yBre+vLFEJ0WhII2sA9U/vSLcyPez7bwIz//Mq+HBfMNI5Pghu+B22DOVNh76+tL1MI0SlJIGgD/aKD+PqOCbx85QhSj5TwyuIU1xQcNQBu/AECouC9C2Hd+64pVwjRqUggaCMWi+LsITHMGBzDvE2ZlFZUu6bgsES4aQEkTICv74Clz7umXCFEpyGBoI1dPCKeovIqFmzNdF2hviFw1ecw6GJY+AisesN1ZQshOjwJBG1sTGIYcSG+fL4mzbUFe1jhwtehz3SYdw9s+Ni15QshOiwJBG3MYlFcNCKOZSk5ZOaXubZwDytc+jYknALf/AFKWrhNphCiU5FAcAJcNCIem4av1qe7vnCrD0z5B1RXwLZvXF++EKLDaVIgUErdpZQKUsabSqm1Sqkp7q5cR5UY4c/I7qG8tWwvT3y/jc/XpFFQVum6G8QMhfBesOlz15UphOiwmtoiuFFrXYDZZSwUuAb4l9tq1QncO7UvIb5ezFm6l3s+28ALC3e5rnClYPClsG8pFGS4rlwhRIfU1ECg7K8zgPe01lucjokWGNsjnB/uPpVtj00jqXsoyfuPuPYGgy4BNGyZ69pyhRAdTlMDwRql1AJMIPjBvhexC3dk77w8PSyM7B7K1owCyqtcNLcAIKKX6SLa9JnryhRCdEhNDQQ3AX8BRmmtSwArcIPbatXJDOsaQkW1jW2u3NsYTPdQxjrI3e3acoUQHUpTA8E4YIfWOk8pdTXwEJDvvmp1LsO7hQKw7oCLu4cGXgQo+OhymP8g7F3i2vKFEB1CUwPBq0CJUmoo8GdgN/Cu22rVyUQH+xAd5MP6VBdvNBMcB+e/bNYiSn4T3jkXDqx07T2EEO1eUwNBldZaA+cDL2mtXwYC3Vetzmd4txDXBwKA4VfB9f+De1PAPxIWy2AvIURtTQ0EhUqpBzDDRr9TSlkweQLhIsO6hrA/t4RcV+5t7Mw7EMbfCXsWwYHf3HMPIUS71NRAcBlQjplPkAnEA0+5rVad0LCuIQBsSHPjPsSjbgK/CPhFWgVCiBpNCgT2h/8HQLBS6hygTGstOQIXGhwfjIdFsf6AGwOBlz9MuBN2/wypq9x3HyFEu9LUJSZmAquAS4GZwG9KqUvcWbHOxs/Lk75RgaxzR57A2aibwTcMfnvNvfcRQrQbnk287v8wcwiyAJRSkcBCQBazcaHh3UL4ZkMGNpvGYnHTxG0vf+hxGqSudk/5Qoh2p6k5AosjCNjlNuO9oonG94ygsKyKbze6eX2g2BGQfwCKc9x7HyFEu9DUh/l8pdQPSqnrlVLXA98B89xXrc5p+qBohsYH8/h32ygqr3LfjeJGmNf0te67hxCi3WhqsvheYDYwxP5vttb6fndWrDOyWBSPnj+IrMJyXvzJhauR1hUzFFCQIYFACNH0HAFa6y+AL9xYF4EZRjozKZ45y/ZyaVJXenUJcP1NvAMhsq+0CIQQQCMtAqVUoVKqoJ5/hUqpgraqZGdz37R++Fg9uPKNlXyWnIrNpl1/k9gRpkWg3VC2EKJdOW4g0FoHaq2D6vkXqLUOaqxwpdQ+pdQmpdR6pVRyPef7KaVWKKXKlVL3tOaDdCQRAd58ePNYYkN8uffzjVzwyjK2HXRx3I0bAcXZkJ9mfq8ogYpi195DCNEutMXIn8la62Fa66R6zh0G7gSeboN6tCuD44P58vbxPH/ZMDLyyjj/pWW8sWSP61oHsfaEccZasNng3fPMKqVCiE6nyTkCd7APSc1SSp19IutxsrJYFBcMj+OU3hE88OUmHp+3jT05RTxx0ZDWFx49CCxWkycoK4C01WD1M0HBIiODhehM3P3/eA0sUEqtUUrNamkhSqlZSqlkpVRydna2C6vXPoQHePP6NSO5ZGQ8X63LoKzSBTuZeXpD1ECzR8FPj4KnD1SWwJG9NdcUZcGhLa2/lxDipObuQDBRaz0CmA7coZQ6tSWFaK1na62TtNZJkZGRrq1hO6GUYsbgaEorq1m977BrCo2zJ4yLc2D6v82xzE015xc8BO+eLwllITo4twYCrXW6/TULmAuMduf9OrpxPSLw8rSweIeLWkWOPMHI62DIZaAstVsA+5ebhLLMQBaiQ3NbIFBK+ds3uUcp5Q9MATa7636dga+XB2MSw1i8I6vxi5ui39lmEbozHgGrL4T3hkP2/0T56ZCfan7O2ema+wkhTkrubBFEAUuVUhswK5d+p7Wer5S6TSl1G4BSKloplQb8CXhIKZWmlGp0WGpnNqlvF3ZnF5N6uKT1hfmFwdnPmFcwCeRMeyBIc1qmOmdH6+8lhDhpuS0QaK33aK2H2v8N1Fo/bj/+mtb6NfvPmVrrePvchBD7zzJR7Tgm9TU5kl92uiFpHjXQLEZXlm92MfP0NSOJcty43IUQ4oSTcYLtTI8If7qG+bouT+AsarB5PbQFUn+DuJEQ3guypUUgREcmgaCdUUoxqU8Xlu/OobzKBcNInUUNNK9pqyFzI3QdbdYkkhaBEB2aBIJ26LQ+kZRUVPPbHhcNI3UIigXfUFj7HtiqoNtYiOhjuotk+QkhOiwJBO3QxN4RBPta+SQ51bUFKwVRgyDX3gKIH2UCAUBuinnN3gkrXnbtfYUQJ5QEgnbIx+rBJSPj+WFzJtmF5UePV7tiHaKoQeY1oo8ZTeQIBNn2IaSLn4AfHjTDS4UQHYIEgnbqyjHdqLJpPltjWgUpWYWMfnwhs5fsbl3B0fZA0HWMeQ3vaSaa5eyE8iLY8b05niZ7HgvRUUggaKd6RgYwrkc4H/52gOLyKu74YB25xRX8e/4O1uxvRe4gZph57T7evHp6Q2iCmUuwcz5UlZrjEgiE6DAkELRjV43tRtqRUi6fvZKdWYW8ctUI4kJ8ufOj9eSXVLas0OhBcP08GDyz5liEfeTQps8hKM7kDtKO2V5CCNFOSSBox6YMiCYiwItN6fn8blJPZgyO4YUrhnOooIwH5m5secEJE8DDaYXyiN4mEKQshIEXmm6jjHVQVdH6DyGEOOEkELRjXp4W7pvWj4tGxHH3mSapO6xrCHee0Zt5mzLZkVnomhtF9gVbpfk36GKIT4Lqcji0qfH3CiFOehII2rmZSV15duYwPD1q/lNePbY7Xh4WPl59wDU3cYwcCusBscMh3r6IrHQPCdEhSCDogML8vZgyMIq569Jds4lNZF/w8LIvVa0gOA4CYyVhLEQHIYGgg7p8VDfySipZsPVQ6wvzCYbblsHEP9Uci0+SQCBEByGBoIMa3zOc+FBfPnFV91BkH/D0qvk9fhQc2QdFTVj8rrJMlqgQ4iQmgaCDslgUlyV1ZVlKLgdyXbB3QV1d7XmC9CbkCb7+Hbx3kevrIIRwCQkEHdglSfFYFEx6ehGDH/mBqc8tYUNqnmsKjxkKFk/Y/fPxr9Ma9i4xy1qXuHiRPCGES0gg6MBign15+coR3DG5F5ckxVNcUcXM11fwv40ZrS/c6gtDL4fkObU3vK8rP83se4yGAytaf18hhMtJIOjgpg+O4c9T+vLIuQP5+o4JDIkP5vcfruPlRSmtL/ysv5tlq7/5A9jso5MKDkKpU6sjfU3Nz3t/bf09hRAuJ4GgEwkP8Ob9m8dwwbBYnvphB8/+uBOtW7FiqV8YTH/SzDL+6TH46nfw3ECYe2vNNRlrwWKFrmNh39LWfwghhAnFiFMAACAASURBVMt5Nn6J6Ei8PT14ZuYwrB4WXvhpF9U2G/dM6YtSqmUFDrwQNn4Cy54HTx8z5yDlJygrAJ8gSF9r1i/qdSYs+ofJE/iFufZDCSFaRVoEnZCHRfHvi4dwxeiuvLxoN4t2ZLW8MKXgvJdgyuNw1wY4+xmzFMXun8Fmg4z1EDsCEiaa6/cvc82HEEK4jASCTspiUTx2/iBign2YvWRP6woLiITxv4fAaLMgnW8Y7JhndjqrKIS4ERA3Ejx9JU8gxElIAkEnZvWwcMOEBFbuOcymtHzXFGrxgD7TYOcPkLrKHIsdYSajdRsjeQIhTkISCDq5y0d3I8Dbkzd+bWWrwFnf6VCWB7+9BlZ/kzcASDgFsrZAcY7r7iWEaDUJBJ1ckI+Vy0Z15btNB0nPK3VNoT1PN4vUHdoMscNMKwFMIADTbSSEOGlIIBDcMCEBgH/8byub0/Ox2TSZ+WV8vT6dVxfv5p3l+/hybRqFZU3c9cw7ABJPMz/HDq85Hj/K5AoWPlp7lnHmJrMekRDihJDho4L4UD9uGJ/Af5fu5fvNmfh7eVBccezy1bdP6sn90/o1rdC+0yHlR5ModrBY4NwX4PVT4ceHzWijX5+Bn/8OZzwCpzitbpqTAv7hZsJaU1UUg9XPjGQSQjSZBAIBwEPnDGDWqT34dVcOaw8cITHCnzGJ4fTs4k9JRTV3fbyOeZsOct/UJs45GDITCg+axLGz6EEw/g9m3kFZPmz71hzPdNpaU2t4a5ppVVzyZtM+wO5F8OFMuPhNGHBe094jhACka0g46RLkw8Uj43n8wsHcfEoPBscH4+flSUSAN+cOiWV/bglbDxY0rTDvQDj9IfDyP/bcafdDSHcTBEbfCr2nQvaOmvMFGWZ9ou3fQXlR4/fKSYHProPqChmVJEQLSCAQTTJlYDQeFsW8TQdbX5iXH1z5CVw4G6b/G7r0g9wUqK4y57O2mdeqUtg5//hllR4xLQGLJ0T2M8tdCCGaRQKBaJIwfy/G9Qhn3qbM1q1P5NClPwy1b30Z2c98mz+yz5zL2mJe/cJh0+fHL+fHv0J+Klz2gVnGInMjVDcxqS2EANwcCJRS+5RSm5RS65VSx+xgoowXlFIpSqmNSqkR9ZUjTg7TB0ezN6eYHYcKXVtwhH2eQfZ285q1DQJjYOgVkLLQfOtvSOoq6HkGdB9nRihVldWU05Af/q/xACNEJ9IWLYLJWuthWuukes5NB3rb/80CXm2D+ogWmjowGouCeRtd0D3kLLKPec2x5wkObYEuA2DQxWbdIkdCua6qCtOl1KW/+d0xVPV43UO2avjtdVj7rmvqLkQHcKJHDZ0PvKtNX8NKpVSIUipGa+3iJ41whYgAb8YkhvPhqlS2ZxZSWFZFRKA3/WMCGdktlDE9wltWsHcgBMWbhLGt2rwmnmoe7KGJsPkLGHHtse/LTQFblQkaAGE9wDvYrHha3/UAeQdMcMncZEYnyVBTIdzeItDAAqXUGqXUrHrOxwGpTr+n2Y/VopSapZRKVkolZ2c3YbN04TbXje+Or5eFA4dLqKy2sXb/EZ6cv4PLZq/klcWt2Owmso/p0jm8B6rLzcNdKRh8idnqsjDz2Pdk25PKjhaBUmYm8/FaBLm7zWvpYShIrzm++N+w9PmW11+IdszdLYKJWut0pVQX4Eel1Hat9ZLmFqK1ng3MBkhKSnJBplK01LRBMUwbFFPrWH5pJX/9ejNPzt+B1WLhllN7NL/gyH6w5m2zLAVAlP1b/pDLYclTsP7D2hPOwOQSlAdE9K45FjscVrwMVeXg6X3sfXKdglXmJgiON62QFS8DGsbcBlaf5tdfiHbMrS0CrXW6/TULmAuMrnNJOtDV6fd4+zHRjgT7Wnnm0qGcPSSGx+dt4/2V+5tfSEQfqCyBnQsAVZNAjugF3SeYPn2brfZ7srZBeM/aD/y4Eabr59CW+u9zeLeZfYyCg/ZJbIe2QHk+lBfArgXNr7sQ7ZzbAoFSyl8pFej4GZgCbK5z2TfAtfbRQ2OBfMkPtE+eHhaev2wYp/frwmPfbmVbUyeeOUTal67Y/p3p6/fyqzk34jo4shf21dnLIGtbzfscjiaM19Z/n9wUE3TCe9bMZnZsluMVCJtlNJHofNzZIogCliqlNgCrgO+01vOVUrcppW6zXzMP2AOkAG8Av3NjfYSbWT0sPH3pUIJ8rdz9yXrKKmuvV1RaUc3na9JYsTv3mHNHl6ouz6/p83cYcB74BMPad2qOVZaafIIjUewQ3NXMP2goT5CbAuG9IHpw7UAQ0g2GXWH2UShrZhATop1zW45Aa70HGFrP8decftbAHe6qg2h7Yf5ePHXJEG54ezXPLNjB/509AK01P2zJ5O//23Z0qWtvTwvTBkXz1CVD8fK0mH2M/SPN0hJRA2sXavU1uYI1b0FxrlmMLnsHoI8NGkqZjXDSko8dFVRZBnmpMPRK0520Za5ZBXX/crPMxaCLYdVs2PG9mewmRCchM4uFy03u14Wrx3bjjV/30uvBeQx65Adue38tgT6evH/TGN68LolLk+L5en0GD3y5qWamsqObp+7DHWCkfS2hjR+b3x2Txuq7tu90c37BQyYYOBzZB2jTIogZYo5t/gJKcqH7eIgfbVoU0j0kOpkTPY9AdFAPnT2AnpEB5BSVU1Zpo2dkADOT4vH0MN89zugfRbi/N//5aReJEX78/vTepu9+36/QZeCxBUYNNPshL38JRl4PWVvN5jdh9YxQSrrRtBhWvGS6lE67zxx3jBgK72Ee+GAmlwEkTDDLZA+6yIwgcrQ8hOgEJBAIt/CxenDDhMTjXvPHM3tz4HAJTy/YyTcbMhhW2Y2rfZKI9Y4jor43nPUYzJkKvz5rEsURfcDDeux1SsG0f0F5ISx63ASLwZfUBIKwnuAbAgHRkLvLLGcRaq/rkMtg2X9g9X9h0v2t+hsI0V5I15A4YZRS/Oviwdw4IZHECH8KY09hZvE9XPPWWvJL6lk4rttY86Be/iKkrT52xJAziwXOexGiBpkHO5hA4B9pggDUdA91n1CTS4gaCP3OMfdw3kVNiA5MAoE4obw9PfjruQN4/ZokXr16JLOvSWJ3VhHXvbWKovKqY99w5qNmyenSI/XnB5x5eJpupMyNZhTR4T0mP+AQPdi8dh9f+32nPwQVRbD0uVZ9NiHaCwkE4qRyap9IXrxyOJvS8znjmcX899c9lFQ4BYSgGDj1HvNz3dFF9RkyEzx9zazl3BTTLeSQcIrJM/ScXPs9Xfqblseq2VBQZ1qL1mYmcl31HXNY9ITpzhLiJCWBQJx0pg6M5sObx5AY4c8/vtvGqU8uIiXLaaey8X+AS96CXmc1XphPsBkWuvFTKDpkJpI59JwM9+2tP+E86S9mQbslT9U+vuIleG4gHNpqftca5j8Iz/SrvyvpyD5TxspXao9gEuIkIoFAnJTG9Ajn41nj+OL2cdg03P7+GoodXUUeVvJ7nIu2eBy9ftehQp6Yt43UwyXHFjbyerN8BdTuGgLwDqi/AmGJplWw8VOz3LXDxk/MXszvnm+2yFz4CKx8GYqzYPfPx5az/CXQ1WZ+RM7Oxj+4rdpsz1lyWAJHXXuX1GxeJFxKAoE4qY3sHsaLVwxnd3YRD3y5iYy8Uu74YC1DH1vAKU8u4tFvt/CHj9Yx5fklvL5kD3/+bAM2W50HaHxSzZDUuoHgePqdAxWFcGC5+b0oyyxUN/RK0DaYfZpJRCfdaGYz7/yh9vuLsmHde6YLCo5dIqOu32bDY2HwRBw8mWgS1o3Zv6Jt92m22WoHxrb0yTXwy1ONX9eY/LSabVEFIIFAtAMTekXw5yl9+WZDBqc9tYiF2w5x44RE+kYF8sFvB/hp2yFuO60n/zejP6v2HuaT5NTaBSgFE+4ycwfq6wZqSI/TwMO75gHv+MY/ZhZc+5WZ8TziWpjxjOmmSvmxdq5g1etmFdSzn4XAWNi3rOF7aW26j7oMNMNkg+LNjOfjqSqHz66Dz65vu4fzz3+H2ZOa954Dv0FWI7vGNaaiGMryzKKBrS3npdHw5S3S4nIi8whEu3D7aT3Zn1tMSUU190/rR9cwsyidI5Hs5+WJ1pqfth/in/O2cUa/LnQJclpOeuhlzV82wssfEk8xgWDaE5DyE/hFQPRQMzz1zzvA0T3VZ6qZ9Zy22gxzLS80yeZ+Z5u9FhImwJ5fGt4M58AKs7DeBa+ZNY8OboTU345fvy1zTd4DYMc8GHjBsdfkHTBBxeKi73z7l5k9pYuyISCy8etzdsG755mRWdfMbfl9HftRtLZrKHUVVBbDli8hYSKMuql15XUQ0iIQ7YLFonjykqG8dOWIo0EATADw8zLfZ5RS/PPCwZRX2bjz43XM35xJblF5rXJW7T3MeS8t5V/fN/Ebau+p5ltozi7TIuh5es1D1SlHQc/Tzd4IjtbDr89AWT5MtO+hkDDR5BFyG9i8Z90HZvXTAeeZ36MHQX5qw/s1a21mQEf0NQ/6NW8fe83OH+D5IbD0maZ91sZobSbyARxc3/j11VXw1e1mH2lHcr2lHAGv8KBZcLCl9i8HZTHddfMfqFmKvJOTQCA6lB6RATx8zgDWHsjjtvfXMPIfCznr2V94+KvN/OnT9cx8fQW7s4p47ZfdfLo69bhlpR0pISXEPsdgyVNQkgO9zqj/Yt8Q6DbO7GdwcCMsewGGXw3xI8357hPNa339+eVF5tv9wAtMKwTMRDho+AF6YIWZHzH2dtM9tWeRmSfhkLsbvrgF0JD8Vk2feHUVfHAprP/ouJ+9XvlpZs8GgIwmBILlL5gWUvxoKMpsOKg1RaHTMN7WtAr2L4eYoXDp22ahw89vkHwBEghEB3TN2O5s+tsUPr9tHPdN60tMiC9frE3jm/UZ3HZaT1Y+eAYTe0Xw0FebWXeg/ofTrkOFnPfSMs59P42KsD5mtBCYb/4N6TPF7LD2uT15fNbfa86F9zRLWtQXCLZ+bborhl9dc+xoIKi7hYfdipfBN9SMbBpxjfmWu/Zdc66iGD652rRYpv7TbMmZstCc2/SpCVZLn2t+H3mWPSgpj8ZbBNk7YNE/YcD5cOq99vc3I0+w5h3TreXgvFVpSwNBVbkJTN0ngH+E+e+Tm9Lw3hVNlbEeVr3RujJOMAkEokPy9vQgKSGM303qxbs3jmbDI1NY8/BZ/GV6PwJ9rLx4xXCigr257f01tecoAHtzirnyv7/hYVF4eVr4ttQ+Azl6CAR0afimvaea19xdMONJ843TQSmTJ9i/rGZSWmGmeWCufcdMdOs6pub6wGgTTDI3HXufI/vMBj4jbzAb+ATFQp9psO59M3nt1Qlm9dVL3oTRs8C/i+k6qq6EX/5tJtHl7Gha944zx65vvc5svEWw+QszbHbG09DFvhSIY4/pxuSnwbd3mpaMQ2EmYM+tHN7brGoflb7W7IftmEne6wxT5u5FLSsPzCiqr++AeffUv692OyGBQHQKVg8Lwb41C9SF+nvxxrVJVNs0F768jEU7siivquardelc9cZKqm2aD28ewxMXDeaTPPvmNw11CzlE9oXI/tD/XBhQT+I2YaLp4pgzFf7VDZ7pCy+PNknh4VfXTiIrZWZO17flpqNbxznROfIGM1fhl39DSFe47APTevGwmrJ3/WDyFkf2wbkvmGCw4ZOm/fEcsraakVeJp0BBmkkYN2TfUtMFE9DFvMcroOktgrTV5jXPacvTwkzzubwCW94i2G9vjXUbZ179wiB2WP3zP5pq+7c1rbZdP7a8nIZUlpo9NNxMRg2JTqtfdBBf/34it7yTzE1vrybY18qRkkoSI/yZfW0SvaMC6R0VyM/DTufpTTuI1VM5v7wKf+8G/m+jFMxaBBZr/SODek8xw0irK2HYlWb1VN9Q888x18BZ1GBInmNaD47EtNameyfxFAiOdyr7LLjqcxM8gmJrlzPyOlj6LCx+wmzlOfRy2PGd2Xdhyj/Mmkz1SUs23SkJE8zvh7aa5TdihpnfD643962rstQ8zMfcWvN3iezb9BZBWrJ5PeIcCA6av51PsBld1RL7l5sd7Zxbaj0mm7kgZQXgE9S88mw2WPwvCO9tuuN2LTDddK7067Pw22tw727w9HJt2U6kRSA6tbgQXz6/fRxXjO7GuJ7hvHfTaH7602kMigs+es0j5w9mXcJNPPjTYcb/62ee+mE7B3LrmcEMZm5BQw/W4Hj48zYTLGY8BaNvMctj9zqj/v+TRw+CqlKT+HVIX2OSwkPqDIVVyjyU6wYBgNCEmtzG5P8z1w653LQgGvo2rDV8cbOZp1BdZYJXzk7zIHWs2tpQ91DaarOJkHNwi+zf/BaB8zf/okMQGGU+S2NdQ9WVZje6WseqzHyGugsM9pxsurBaMilv29emlXTa/eZvv3tR0+dzfHEzzL2t8evS15gEfVYrR101QloEotPz8/Lk8QsHN3g+0MfKBzePZe2BI7y2eDevLN7Ny4t2MyYxjCBfK2lHSimtqGJsj3Am9Y1kUt8u+FhrhpZqrdHaDIFtFseieoc2m7kIYJLWHt6m+6k5zvybeQj2OtP83nuKaYls/NgkuetKS6755r37ZxPEbJWmTj7BZoZ2QzmGfUtN8rrb2JpjXfrB+vfN0hnO38jrqqqAgxvMZyzJMSOqvANM11DP002X1s4fzLfxhuZGfHW7Gbl16y8mMANkbjAJ+e4Tal/bdQxY/cyoq34zGq5XXY7WQERfs5mR1dfkeg6sMBMRG7N/+bF7aexfYYYMD5lZc8wxXDdjrenGchNpEQjRRCO6hTL72iSW3X8690zpw+HiCg7klhAb7EPvqEC+23iQ295fy03vrD66zEVVtY0r3lhJ/7/OZ9rzS7jr43Xszy1u2g0j+5kltx190NWVJgnbd7p5GDdHzFAzesfRZeXpBQMvMknnsvxjr9/4CXj61AQLxzfSLvZ8ScywhlsEjvyAcx0j7UuGZzXSPXRos5l30MeeeM87YLpdygsgIMqsAVVdAYUZ9b+/ohi2fWuS4Yv+WXM85SfzWrdF4OltgkNzE8a5KSYhP/Z2023XY5IJUrsWNP7eihIzkisv1fw3dVj6LPzvTzWz00uP1HzOjHXNq18zSSAQopliQ3z5/em9+fFPp/HD3afy5vWjeOPaJNb+9SwePmcAy1JymbPMfJv+z0+7WLnnMGcPjiE2xJeft2Vx8asr2JpR0PiNPL1NHiHTHgh2LzL7K9ftFmqpEdeYh27dOQVHA84MGHSJCRapv5mgFGFvmcQOMwnj4pza73XkBxIm1j7e1JFDjvzA4EvM65F9NaNxAmNM15DjeH1SFprPFDPMrBSbvgY2fma+vfeYZEZj1dVzshnpVTcpu+Fj2Pxl/fdxLCDo6CbzDjABpSmBwFF3XV17iGxuilnbKmeX+d0RND19JRAI0V5YPSzcOCGBKQOieHL+DuYs3ctLi1K4dGQ8z142jDnXj2LuHeOxeigue30Fi3ZkHbNAns2m+WnbIW54axWfr0kz8wkyN8KO+bDsefMN3dG901qxwyF+lFkKw2arOZ7yE5QeNgFn6OXmwbrmHdMd5MhlOBLGdVsFacnH5gcAguLAO6j+PEFacs034/RkM9/C0YWTt98pEETXbCnaUJ5g27dm2O01c00L4uOrzLpC3cebkVT16WHfj2JPnVbBosfhp8fqf0+u/WEd3rvmWO8pJkA0lsNwXi/J0f1WVVGTHE+3B0PHiLEB55ug0JoZ1Y2QQCCEC5ntN4cQ7Gflsf9tJTHCn0fPr9lAp1eXQL64fTxdgry54a3VjH3iJx74ciOPf7eVB+duYtp/lnDTO8ks253LfZ9vYIdKMCNmPrrMzEEYf6drR4+MvtU8mPY4JY03fgK+YSaJHTfSBIDq8ppuITBdP56+8MODtZPZ9eUHzB/GPnKoTiA4tAX+ewZ8f5/5PW21WS3WL9wMOT2yv2ZWcWC0GYqqPOofOVRVbvIHfWeYPMQ5z5n39jwdrvy04SXHu/Q3cy2cE8Zl+ebb+pG9Zl5DXTkpJtA4jzRydGdt+6b++zg4/70cQSNvv2khgGnFgHn4eweb9apsVfUPJXYRCQRCuFiYvxfPzhxK7y4BvHjF8KNrITnEhvjy9e8n8txlQxnZPZRv1mfw3sr9LNiSia+XJ89dNpTkh85kcHwIV67tx56JT1N1/XwK7t7Lmm438N9f9/DPedvIKihroAbNMOB88xD8bbb5veSwWcBu0MUmmekYYQQQ5RQIfILgqs/MyKM3TjdzErZ8Bdv/d2x+wCGy37E5gj2LzWvyHDOB7PAe00pRCkK6m24UxzpDgdFmRFZI1/q7hvYuMbmE/vb1mvpOh9+thCs+NhPvGqKUCT7O3S/OD936RhTl7KzpJnMI7wmJp8Hif9c87LU2n83R5QXmM/qGmRyM43M41qDyDXUKBPbhunEjzO/prZwBfRwyakgINzildyQ//qnh0SMB3p5cODyeC4fHN3jNW9eP4pJXl3P6Qh9YeBhYcfScRcE36zN449okBsfXfujml1aSW1ROj8gGvgE78/SCpBvglydNMFj2vOnacV7uYtgVZvkKRxeKQ+IpcMvP8PGVMHdWzfHJ/1f/vbr0N/szOK9cuneJ6ff3DYP/3W2OxY8yr6H2QFDYyzw0fULsxxPr737Z+rXpfnIetdPYvtYOscNhx/c18wkceRlPH7OPxNDLa1+fu6v+SYMXvAKvjocvZ8EN82DevWY0UY/JZulyqNk7u7yg5nM48gIDLzR/68pSEwgGXWy61fwj3ZonkEAgxEkqzN+LD24ZwyerU/FQCh+rB13D/BjRLYScogpueTeZS19fznMzhzF9cAwAZZXVXDF7JVsPFjC+ZzjXjkuguLyKVXsPU1lt475p/YgO9ql9o5E3mFnH399rchKXvl17qGJwPNxdz1IXYEbx3PyTeUj5hphluhtahsPRtZSebL6tV1eZYZSDLoIJf4TXTjE7yTnuHZpglu4uzDTdMI4RT6EJ5qFfVW5aFKVHzD13zDPdM57ezf9jxw4HtMnHJEyEQ5tMcOo+HvbW2VCoONfcM6L3seUEx5suqc9vhJfHmK6lwFjTInBMDMzdbYJVaV5NF1duiukO63WmaUHsnG+6p7oMMJ87drgEAiE6q5hgX/54Zp9jjncJ8uHr30/g1vfWcMeHa3l25jDOHxbLw19tZuvBAq4d150FWw5x2/ummyHIx5PKas3indk8fekQ+scE8evOHPbkFDOhVzjjpj6JRVeR0n0mmYVVjK+24enRxJ5jL7+a2cfH032Cebhu/MQEgoMbzLfixFNNQJn5jnkQO1ZgDeluxv4f2mJGDDmEJZpk9lO9obzO0FdHt1BzHU1+rzOBIHOzmdCXcIrp7so7ACHdzDWOEUPh9QQCMN/id/0IGz6CMx81XVpzbzXdYmE9zJDQsJ4mmOxZbLqPcnebVkKcfbXate+ZV0fwjB1uRkQ55lW4mAQCIdqpiABv3rtpNDe+vZo/fbqexTuy+Gp9Bn84vRd/ntLXPpQ1hy6BPvSLDmRvbjG//3AdN75d01+tFLz2y24CfeJRQEGZ2RXt3KGxPDdzaNODQVN4eplhoWveMQ/BfUvMcccIo15n1F7PKbS7ec3aWrsbJmGiSRonTDQP3dBEs9dDZQn0OM7qsMcTEGnKzFhnvrlnbTNdZo5hsPuWmmVBoGbEUH0tAofzXjS74nXpX7M8eNqqmlZNeA+Tj6kqNS2e3BTTGgiMNvtLOGZ8O7q2Yoeb7VEzN0H3cS37jMchgUCIdszPy5O3rh/NTe+s5qv1GZzSO+JoC8LqYWFS35pump6RAcz93XjeWrYPDwuc2ieS7mH+LE3JYeHWQ1gsZo/otCMlPL9wF9U2G/+5fDjWOsGgqtrG0pQcft6exYhuoZw7NBaPps6aHnqFGa665SuTH4js33BXkmPOANQe/x83Eu6uszx3RDP2om5I7DATCHJ3mwd01CDzjdw3rHYgyNllZj47Wgj18bDWPMRDE02XWeoq8wqmZeBtz+1kbjL7NYT3tH++EWaORmBMzSzs2OHmNWOdBAIhxLF8vTx487pRfLYmlfMaeSj7WD24fVLPWsfOGhDFWQOiah0L8PbkH99tY1P6YuJCfAnx9aJaa8qrbGw7WEB2YTlWD8W7K/bz4s+7uHdqX6YNiqFRscPNsgxr3zVDSYcfZ5E25wdtfRPBXC12uJmH4FilNHqQWcYiYULtPEHOLvMgd96h7niUMktZpK4yI6fAdA1524eeOvaKCLcHs7iRZgiqc6I70D63ou6yFC4igUCIDsDXy4NrxyW4rLybT+lBmL8XP2zJ5HBxBbuzi/D0sODtaWFUQijnDY1jUt9Ift6exXM/7jRLa0xM5MEZ/fGwKFbuyeWT1akcOFxC2pESIgK8mTIgmmmDouk77ApY+Ddzo8R6Vl118PI3o2WKs80kM3dzfOte94GZRe14aCecagLEkX2mlZK7q/aciqboOsqs+Jq6ynwmnyAzIklZIMW+fLVzIIBj73HDvJZ8qiaRQCCEqNdFI+K5aETDw1sBZgyOYcqAKB6ft403l+5lT3YRHhbFwm1ZhPl70ScqgFN6R7Ivp5jnf9rJcwt3cueo4dytLCitj10Erq7QBBMI2qJF4EgYpyebh7Bj9JFjA5tVb5jF+47sM/MvmsOx6dCuBTXzAjy9zCijw3tM+WH2WdNxI01QckxQawNuDwRKKQ8gGUjXWp9T51x3YA4QCRwGrtZa1zONTwhxsvL0sPDIuQPpERnA377Zgp/Vg/um9eXGCYm1VmHNLizn5UUpvLB8HxODxzAgpIrNmZrCMjNhzNOi8PXyIDrIh+hgH/PekO5mtnFgE7qdWssvzASeI/tqtgoF03c/7CqT2+gx2czybWjEUENih5tWhq3SdAs5hPUwI5KCu9aslOrlB7MWt+6zNFNbtAjuArYB9e36NMAvBwAACzVJREFU8DTwrtb6HaXU6cATgIt3dhBCtIVrxnZnXI9wwv29CPU/dhmMyEBv/nbeQIZ3C+GWL35HeX4VZbNXNljeyO6hPBoQyiCgxDsCa7XtmMR1fbZmFJBbXM4pvSOb/yFiR9gDwcDaxyc/aBbi+/ZO83vdWcWNsfqarU4z1poRQw6hicDimkTxCeLWQKCUigfOBh4H/lTPJQOcji8CvnJnfYQQ7tWrS+Nj3M8fFsewriFsySggxNdKoI8VpaDKpikqqyKzoIwDucXM25zJLfuHMNFjFp898RtgJtn1igygZ5cAekb60yPSn5Hdwgj2M0nUrRkFXPb6CgrLqzh7SAyPnTeQ8ABv8ksryS+pJMTfSoCXJ9szC1m+O4eMvDIm9Y1kXM9wE2Rih8OWLyF6EGWV1Xh5WMw+EsFxMO53ZuIdHB2lVFVtY+Wew+w4VIiflwcB3p6c1jeSIJ96krpdx5hAEOYUCBzdQeG1Rz1prcksKGPnoSL8vDwYlXCcPRxcwN0tgueB+4DABs5vAC4C/gNcCAQqpcK11rnOFymlZgGzALp1O86QLSFEu9A93J/u4f7Hvebus/qwOb2A3/ZO5P5qTWW1jYy8UlKyipi36SD5pWbF0hA/Kw9M78e4HhFc99YqAnw8uXZ8d2Yv2cOvO7Px8vQgp6j8aLlKmTlcAF4eFuYs20uIn5WekQHE6q5c5jOJhz8tZ2/BfBIj/Pn3xUMYnRhmZj+veQetLKzPsvHZmk3M32yS6c76RAXwwc1jiQysPcO5MHY8gbzKp6lBrNyynpKKaiZUWrgGWJQTzNZFKeSVVLA5vYAtGfkUlFUdfe8fz+zNXWf0RtW3BaoLKK1141e1pGClzgFmaK1/p5SaBNxTT44gFngJSASWABcDg7TWeQ2Vm5SUpJOTkxs6LYToJA4XV7A9s4DnftzJ6n1H8PK04ONp4fPbx9MnKpAdmYW8+PMu/Lw86BEZQJi/F/klleSVVpAYEcCEXuGE+nmxZGc287dkklVQTkW1WY47PtSX+BBfvlyXTnpeKZeP6kZssA/BB5eRnp7K60dG4GO1cGb/KM4ZEsPoxHDKq6rZnF7AnR+tIzbEh7dvGM22gwV8syGDtfuPkJFfSoLKZJ+OITrIhyBfT7yKM/ig8s9cWfEgW3QiXp4W+scEMTA2iH7RgfTuEsgXa9P4fE0aV47pxt/PH9T0ORt1KKXWaK2T6j3nxkDg6O+vAnwwOYIvtdZXN3B9ALBda33cYQoSCIQQzmw2zWdrUnl/5QEeOXcASS7sRikur+KpH3bwzop9aA2B3p70igrg0pFdOXdoDIH1dAGt2nuYG95aRXGFWVY6zN+Lib0iGBQXxMDYYPrHBBFWJ4dis2kqqm14WtQxs7m11jz1ww5eWbybGyYk8Mi5dfIXTXRCAkGdCkyi/hZBBHBYa21TSj0OVGut/3q8siQQCCHaWmFZJV6eFrw9mzaJbH1qHp8mp3JW/ygm9o5oUpK7MR/8tp+JvSIa7VJryPECQZvPI1BKPQYka62/ASYBTyilNKZr6I62ro8QQjSmvm/+xzOsawjDuoa4tA5Xjenu0vKctUmLwJWkRSCEEM13vBaB7FAmhBCdnAQCIYTo5CQQ/H97dxdrR1WGcfz/2Eql1NjiB9GW0CKNWogUNKSKGgImtkgoFxCrFVFJvCERjInSVGP0zmhETRAwoBRtgFCLNiQSoJIaLtpSsJbaUimgckixNUIVjXw+Xqx1dHs+0r3b45kzneeXnJw9a2bPWW/efebde83sNRERHZdCEBHRcSkEEREdl0IQEdFxKQQRER3Xuu8RSDoA/PEwn/4m4C8T2J2mHU3xJJapKbFMTYcTy0m2x5ybu3WF4EhI2jbeFyra6GiKJ7FMTYllaproWDI0FBHRcSkEEREd17VC8MOmOzDBjqZ4EsvUlFimpgmNpVPnCCIiYrSufSKIiIgRUggiIjquM4VA0lJJeyTtlXR10/0ZhKQTJd0vaZek30m6srYfL+leSY/V33Oa7mu/JE2T9BtJd9XlBZK21PzcLumYQ+1jKpA0W9I6SY9K2i3pfW3Ni6Qv1NfXTkm3Snpdm/Ii6UeS9kva2dM2Zi5UfL/GtUPSmc31fLRxYvlWfZ3tkHSnpNk961bVWPZI+sigf68ThUDSNOBaYBmwCPi4pEXN9mogLwNftL0IWAJcUft/NbDR9kJgY11uiyuB3T3L3wSusX0K8CxweSO9Gtz3gLttvxM4nRJT6/IiaS7weeC9tk8DpgEraFdebgaWjmgbLxfLgIX153PAdZPUx37dzOhY7gVOs/1u4PfAKoB6LFgBnFqf84N6zOtbJwoBcBaw1/YTtl8EbgOWN9ynvtneZ/vh+vjvlIPNXEoMa+pma4CLmunhYCTNAz4K3FiXBZwLrKubtCIWSW8APgTcBGD7RdvP0dK8UG5de6yk6cBMYB8tyovtXwN/HdE8Xi6WA7e42AzMlvTWyenpoY0Vi+17bL9cFzcD8+rj5cBttl+w/SSwl3LM61tXCsFc4Kme5aHa1jqS5gNnAFuAE2zvq6ueAU5oqFuD+i7wJeDVuvxG4LmeF3lb8rMAOAD8uA5z3SjpOFqYF9tPA98G/kQpAAeBh2hnXnqNl4u2HxM+C/yyPj7iWLpSCI4KkmYBPwOusv233nUu1wFP+WuBJV0A7Lf9UNN9mQDTgTOB62yfAfyDEcNALcrLHMo7ywXA24DjGD000WptycWhSFpNGS5eO1H77EoheBo4sWd5Xm1rDUmvpRSBtbbX1+Y/D3+crb/3N9W/AZwNXCjpD5QhunMp4+yz65AEtCc/Q8CQ7S11eR2lMLQxLx8GnrR9wPZLwHpKrtqYl17j5aKVxwRJnwYuAFb6v18CO+JYulIIHgQW1isgjqGcWNnQcJ/6VsfQbwJ22/5Oz6oNwGX18WXALya7b4Oyvcr2PNvzKXn4le2VwP3AxXWztsTyDPCUpHfUpvOAXbQwL5QhoSWSZtbX23AsrcvLCOPlYgPwqXr10BLgYM8Q0pQkaSllSPVC2//sWbUBWCFphqQFlBPgWwfaue1O/ADnU860Pw6sbro/A/b9A5SPtDuA7fXnfMrY+kbgMeA+4Pim+zpgXOcAd9XHJ9cX717gDmBG0/3rM4bFwLaam58Dc9qaF+DrwKPATuAnwIw25QW4lXJ+4yXKp7XLx8sFIMqVhI8Dj1Culmo8hkPEspdyLmD4GHB9z/arayx7gGWD/r1MMRER0XFdGRqKiIhxpBBERHRcCkFERMelEEREdFwKQUREx6UQREwiSecMz7gaMVWkEEREdFwKQcQYJH1S0lZJ2yXdUO+f8Lyka+qc/Rslvbluu1jS5p554ofnvD9F0n2SfivpYUlvr7uf1XMPg7X1m7wRjUkhiBhB0ruAjwFn214MvAKspEzEts32qcAm4Gv1KbcAX3aZJ/6Rnva1wLW2TwfeT/mmKJTZY6+i3BvjZMqcPhGNmX7oTSI65zzgPcCD9c36sZTJyl4Fbq/b/BRYX+9JMNv2ptq+BrhD0uuBubbvBLD9L4C6v622h+rydmA+8MD/P6yIsaUQRIwmYI3tVf/TKH11xHaHOz/LCz2PXyH/h9GwDA1FjLYRuFjSW+A/9709ifL/MjwT5yeAB2wfBJ6V9MHafimwyeVOckOSLqr7mCFp5qRGEdGnvBOJGMH2LklfAe6R9BrKDJBXUG48c1Zdt59yHgHK9MbX1wP9E8BnavulwA2SvlH3cckkhhHRt8w+GtEnSc/bntV0PyImWoaGIiI6Lp8IIiI6Lp8IIiI6LoUgIqLjUggiIjouhSAiouNSCCIiOu7fsH/tq8E9TckAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIvbXL32hN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model = student_model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Nadam(lr=0.0001), metrics=['accuracy'])\n",
        "model.save(\"improved_mobilenet_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCXE1Nm45huL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ead3953f-69c8-4f92-ac63-29d66727f1dd"
      },
      "source": [
        "# Evaluate model\n",
        "train_score = model.evaluate_generator(student_train_generator, verbose=1)\n",
        "print(\"Training loss: \", train_score[0])\n",
        "print(\"Training accuracy: \", train_score[1])\n",
        "\n",
        "validation_score = model.evaluate_generator(student_validation_generator, verbose=1)\n",
        "print(\"Validation loss: \", validation_score[0])\n",
        "print(\"Validation accuracy: \", validation_score[1])\n",
        "\n",
        "test_score = model.evaluate(student_test_generator, verbose=1)\n",
        "print(\"Testing loss: \", test_score[0])\n",
        "print(\"Testing accuracy: \", test_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-46b171995974>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "201/201 [==============================] - 110s 548ms/step - loss: 0.1585 - accuracy: 0.9746\n",
            "Training loss:  0.15845470130443573\n",
            "Training accuracy:  0.974582850933075\n",
            "27/27 [==============================] - 14s 520ms/step - loss: 0.7990 - accuracy: 0.8223\n",
            "Validation loss:  0.7989630103111267\n",
            "Validation accuracy:  0.8222748637199402\n",
            "844/844 [==============================] - 9s 10ms/step - loss: 0.6609 - accuracy: 0.8566\n",
            "Testing loss:  0.6609293818473816\n",
            "Testing accuracy:  0.8566350936889648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJ6NpZE8AzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test images\n",
        "predictions = []\n",
        "\n",
        "for filename in student_test_generator.filenames:\n",
        "    img = load_img(test_dir+filename, target_size=(image_width, image_height))\n",
        "    img = img_to_array(img)/255\n",
        "    img_expand = np.expand_dims(img, axis=0)\n",
        "    predictions.append(model.predict(img_expand)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhHvvZGaHKQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get index of largest probability\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get coin directory name from index \n",
        "directories = dict((v, k) for k, v in student_train_generator.class_indices.items())\n",
        "predicted_dir = [directories.get(k) for k in predicted_indices]\n",
        "\n",
        "# Get label name from coin directory name\n",
        "with open(data_dir + 'cat_to_name.json', 'r') as json_file:\n",
        "    labels = json.load(json_file)\n",
        "predicted_labels = [labels.get(str(k)) for k in predicted_dir]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4DLt4o3H78s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8a478709-03e0-44c3-dbda-3ee7c478e75e"
      },
      "source": [
        "# Save predicted labels as CSV file\n",
        "filenames = student_test_generator.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames, \"Predictions\": predicted_labels})\n",
        "results.to_csv(\"improved_mobilenet_results.csv\", index=False)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/021__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/022__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/027__1 Cent_australia.jpg</td>\n",
              "      <td>2 Cents,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/036__1 Cent_australia.jpg</td>\n",
              "      <td>1 Cent,Australian dollar,australia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10/005__5 Centavos_brazil.jpg</td>\n",
              "      <td>5 Centavos,Brazilian Real,brazil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Filename                          Predictions\n",
              "0    1/021__1 Cent_australia.jpg   1 Cent,Australian dollar,australia\n",
              "1    1/022__1 Cent_australia.jpg   1 Cent,Australian dollar,australia\n",
              "2    1/027__1 Cent_australia.jpg  2 Cents,Australian dollar,australia\n",
              "3    1/036__1 Cent_australia.jpg   1 Cent,Australian dollar,australia\n",
              "4  10/005__5 Centavos_brazil.jpg     5 Centavos,Brazilian Real,brazil"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZlj71Kl_2WO",
        "colab_type": "text"
      },
      "source": [
        "# **Convert to TFLite**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVWQuD08_1hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a956ee3-bcef-48b5-ccf3-7d3551ead308"
      },
      "source": [
        "# Create converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "open(\"improved_mobilenet_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3054968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX-yMWB34O4C",
        "colab_type": "text"
      },
      "source": [
        "# **Copy model to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcyZNaSi4bkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fcd4b4f4-61ad-4c9b-e1d3-0ac9a75eb733"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp improved_mobilenet_model.h5 \"/content/drive/My Drive/Bangkit project/models\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}